import { Groq } from "groq-sdk"

// Danh s√°ch API keys
const API_KEYS = [
  process.env.NEXT_PUBLIC_GROQ_API_KEY_1 || "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",
  process.env.NEXT_PUBLIC_GROQ_API_KEY_2 || "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",
  process.env.NEXT_PUBLIC_GROQ_API_KEY_3 || "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",
  process.env.NEXT_PUBLIC_GROQ_API_KEY_4 || "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",
  process.env.NEXT_PUBLIC_GROQ_API_KEY_5 || "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",
].filter((key) => key && !key.includes("account") && key.startsWith("gsk_"))

const SINGLE_MODEL = "meta-llama/llama-4-scout-17b-16e-instruct"

// Cache ƒë∆°n gi·∫£n
const testResultsCache = new Map<string, boolean>()

// Function ∆∞·ªõc t√≠nh s·ªë tokens
const estimateTokens = (text: string): number => {
  return Math.ceil(text.length / 4)
}

// üî• ENHANCED: Comprehensive field extraction v·ªõi data integrity protection
const extractPlainTextFromField = (value: unknown, fieldName?: string): string => {
  // üîç DETAILED LOGGING for debugging
  const logExtraction = (input: unknown, output: string, method: string) => {
    if (fieldName && (output === "" || output === "null" || output === "undefined")) {
      console.warn(`‚ö†Ô∏è Field "${fieldName}": ${method} resulted in empty output`)
      console.warn(`   Input type: ${typeof input}`)
      console.warn(`   Input value:`, input)
    }
  }

  // 1. Handle null/undefined
  if (value === null || value === undefined) {
    logExtraction(value, "", "null/undefined check")
    return ""
  }

  // 2. Handle primitive types
  if (typeof value === "string") {
    const result = value.trim()
    logExtraction(value, result, "string")
    return result
  }

  if (typeof value === "number") {
    const result = String(value)
    logExtraction(value, result, "number")
    return result
  }

  if (typeof value === "boolean") {
    const result = value ? "Yes" : "No"
    logExtraction(value, result, "boolean")
    return result
  }

  // 3. Handle Date objects
  if (value instanceof Date) {
    const result = value.toISOString()
    logExtraction(value, result, "Date object")
    return result
  }

  // 4. üî• COMPREHENSIVE OBJECT HANDLING
  if (typeof value === "object") {
    try {
      const jsonStr = JSON.stringify(value)

      // üîç Log original object for debugging
      console.log(`üîç Processing object field "${fieldName}":`, jsonStr.substring(0, 200))

      // Handle empty/null objects
      if (jsonStr === "null" || jsonStr === "{}" || jsonStr === "[]") {
        logExtraction(value, "", "empty object")
        return ""
      }

      // üî• PATTERN 1: Lark Base Text Objects
      // Format: [{"type":"text","text":"Intel Pentium"}] or {"type":"text","text":"value"}
      if (jsonStr.includes('"type":"text"') && jsonStr.includes('"text":')) {
        const textMatches = jsonStr.match(/"text":"([^"]*(?:\\.[^"]*)*)"/g)
        if (textMatches) {
          const texts = textMatches
            .map((match) => {
              const textMatch = match.match(/"text":"([^"]*(?:\\.[^"]*)*)"/)
              return textMatch ? textMatch[1].replace(/\\"/g, '"').replace(/\\\\/g, "\\") : ""
            })
            .filter((text) => text.length > 0)

          if (texts.length > 0) {
            const result = texts.join(", ")
            console.log(`‚úÖ Extracted text objects: "${result}"`)
            logExtraction(value, result, "text objects")
            return result
          }
        }
      }

      // üî• PATTERN 2: Lark Base Option Objects
      // Format: {"id":"optr5hYAsF","text":"SSD-128"} or [{"id":"opt1","text":"Value1"}]
      if (jsonStr.includes('"text":') && (jsonStr.includes('"id":') || jsonStr.includes('"color":'))) {
        const textMatches = jsonStr.match(/"text":"([^"]*(?:\\.[^"]*)*)"/g)
        if (textMatches) {
          const texts = textMatches
            .map((match) => {
              const textMatch = match.match(/"text":"([^"]*(?:\\.[^"]*)*)"/)
              return textMatch ? textMatch[1].replace(/\\"/g, '"').replace(/\\\\/g, "\\") : ""
            })
            .filter((text) => text.length > 0)

          if (texts.length > 0) {
            const result = texts.join(", ")
            console.log(`‚úÖ Extracted option objects: "${result}"`)
            logExtraction(value, result, "option objects")
            return result
          }
        }
      }

      // üî• PATTERN 3: Lark Base User Objects
      // Format: {"id":"user123","name":"John Doe","email":"john@example.com"}
      if (jsonStr.includes('"name":') && (jsonStr.includes('"id":') || jsonStr.includes('"email":'))) {
        const nameMatches = jsonStr.match(/"name":"([^"]*(?:\\.[^"]*)*)"/g)
        if (nameMatches) {
          const names = nameMatches
            .map((match) => {
              const nameMatch = match.match(/"name":"([^"]*(?:\\.[^"]*)*)"/)
              return nameMatch ? nameMatch[1].replace(/\\"/g, '"').replace(/\\\\/g, "\\") : ""
            })
            .filter((name) => name.length > 0)

          if (names.length > 0) {
            const result = names.join(", ")
            console.log(`‚úÖ Extracted user objects: "${result}"`)
            logExtraction(value, result, "user objects")
            return result
          }
        }
      }

      // üî• PATTERN 4: Lark Base Attachment Objects
      // Format: {"name":"file.pdf","url":"https://...","size":1024}
      if (jsonStr.includes('"name":') && (jsonStr.includes('"url":') || jsonStr.includes('"size":'))) {
        const nameMatches = jsonStr.match(/"name":"([^"]*(?:\\.[^"]*)*)"/g)
        if (nameMatches) {
          const names = nameMatches
            .map((match) => {
              const nameMatch = match.match(/"name":"([^"]*(?:\\.[^"]*)*)"/)
              return nameMatch ? nameMatch[1].replace(/\\"/g, '"').replace(/\\\\/g, "\\") : ""
            })
            .filter((name) => name.length > 0)

          if (names.length > 0) {
            const result = names.join(", ")
            console.log(`‚úÖ Extracted attachment objects: "${result}"`)
            logExtraction(value, result, "attachment objects")
            return result
          }
        }
      }

      // üî• PATTERN 5: Lark Base Link Objects
      // Format: {"text":"Display Text","link":"https://example.com"}
      if (jsonStr.includes('"link":') && jsonStr.includes('"text":')) {
        const linkData = []
        const textMatches = jsonStr.match(/"text":"([^"]*(?:\\.[^"]*)*)"/g)
        const linkMatches = jsonStr.match(/"link":"([^"]*(?:\\.[^"]*)*)"/g)

        if (textMatches && linkMatches) {
          const texts = textMatches.map((match) => {
            const textMatch = match.match(/"text":"([^"]*(?:\\.[^"]*)*)"/)
            return textMatch ? textMatch[1].replace(/\\"/g, '"').replace(/\\\\/g, "\\") : ""
          })
          const links = linkMatches.map((match) => {
            const linkMatch = match.match(/"link":"([^"]*(?:\\.[^"]*)*)"/)
            return linkMatch ? linkMatch[1].replace(/\\"/g, '"').replace(/\\\\/g, "\\") : ""
          })

          for (let i = 0; i < Math.max(texts.length, links.length); i++) {
            const text = texts[i] || ""
            const link = links[i] || ""
            if (text || link) {
              linkData.push(text ? `${text} (${link})` : link)
            }
          }
        }

        if (linkData.length > 0) {
          const result = linkData.join(", ")
          console.log(`‚úÖ Extracted link objects: "${result}"`)
          logExtraction(value, result, "link objects")
          return result
        }
      }

      // üî• PATTERN 6: Arrays of primitive values
      if (Array.isArray(value)) {
        const arrayValues = value
          .map((item) => extractPlainTextFromField(item, `${fieldName}[array_item]`))
          .filter((item) => item && item.trim() !== "")

        if (arrayValues.length > 0) {
          const result = arrayValues.join(", ")
          console.log(`‚úÖ Extracted array values: "${result}"`)
          logExtraction(value, result, "array values")
          return result
        }
      }

      // üî• PATTERN 7: Generic object with valuable properties
      // Extract all string/number values from object
      const extractObjectValues = (obj: any, prefix = ""): string[] => {
        const values: string[] = []

        for (const [key, val] of Object.entries(obj)) {
          if (val === null || val === undefined) continue

          if (typeof val === "string" && val.trim() !== "") {
            values.push(val.trim())
          } else if (typeof val === "number") {
            values.push(String(val))
          } else if (typeof val === "boolean") {
            values.push(val ? "Yes" : "No")
          } else if (typeof val === "object" && val !== null) {
            // Recursive extraction for nested objects
            const nestedValues = extractObjectValues(val, `${prefix}${key}.`)
            values.push(...nestedValues)
          }
        }

        return values
      }

      const objectValues = extractObjectValues(value)
      if (objectValues.length > 0) {
        const result = objectValues.join(", ")
        console.log(`‚úÖ Extracted object values: "${result}"`)
        logExtraction(value, result, "generic object")
        return result
      }

      // üî• FALLBACK: Return formatted JSON if no patterns match
      const fallbackResult = jsonStr.length > 200 ? jsonStr.substring(0, 200) + "..." : jsonStr
      console.warn(`‚ö†Ô∏è Using fallback JSON for field "${fieldName}": ${fallbackResult}`)
      logExtraction(value, fallbackResult, "fallback JSON")
      return fallbackResult
    } catch (error) {
      console.error(`‚ùå Error parsing field "${fieldName}":`, error)
      console.error(`   Original value:`, value)

      // üî• EMERGENCY FALLBACK: Convert to string
      const emergencyResult = String(value).substring(0, 100)
      logExtraction(value, emergencyResult, "emergency fallback")
      return emergencyResult
    }
  }

  // üî• FINAL FALLBACK for unknown types
  const finalResult = String(value).substring(0, 100)
  console.warn(`‚ö†Ô∏è Unknown type for field "${fieldName}": ${typeof value}`)
  logExtraction(value, finalResult, "final fallback")
  return finalResult
}

// üî• ENHANCED: CSV Conversion v·ªõi data integrity validation
const convertToCSV = (data: Array<{ recordId: string; fields: Record<string, unknown> }>): string => {
  if (data.length === 0) return ""

  console.log(`üìä ===== ENHANCED CSV CONVERSION v·ªõi DATA INTEGRITY =====`)
  console.log(`üìä Converting ${data.length} records to CSV format...`)

  // üîç STEP 1: Analyze all fields across all records
  const allFieldNames = new Set<string>()
  const fieldValueSamples: Record<string, unknown[]> = {}
  const fieldStats: Record<string, { totalValues: number; emptyValues: number; uniqueTypes: Set<string> }> = {}

  data.forEach((record, recordIndex) => {
    Object.entries(record.fields).forEach(([fieldName, fieldValue]) => {
      allFieldNames.add(fieldName)

      // Collect samples for analysis
      if (!fieldValueSamples[fieldName]) {
        fieldValueSamples[fieldName] = []
        fieldStats[fieldName] = { totalValues: 0, emptyValues: 0, uniqueTypes: new Set() }
      }

      fieldValueSamples[fieldName].push(fieldValue)
      fieldStats[fieldName].totalValues++
      fieldStats[fieldName].uniqueTypes.add(typeof fieldValue)

      if (fieldValue === null || fieldValue === undefined || fieldValue === "") {
        fieldStats[fieldName].emptyValues++
      }

      // Log first few samples for debugging
      if (fieldValueSamples[fieldName].length <= 3) {
        console.log(`üîç Field "${fieldName}" sample ${fieldValueSamples[fieldName].length}:`, fieldValue)
      }
    })
  })

  const fieldNames = Array.from(allFieldNames).sort()
  console.log(`üìã Found ${fieldNames.length} unique fields:`, fieldNames)

  // üîç STEP 2: Analyze field quality
  console.log(`üìä Field Quality Analysis:`)
  fieldNames.forEach((fieldName) => {
    const stats = fieldStats[fieldName]
    const fillRate = (((stats.totalValues - stats.emptyValues) / stats.totalValues) * 100).toFixed(1)
    const types = Array.from(stats.uniqueTypes).join(", ")
    console.log(`  "${fieldName}": ${stats.totalValues} values, ${fillRate}% filled, types: ${types}`)
  })

  // üîç STEP 3: Create consistent headers
  const headers = ["STT", ...fieldNames]
  const csvHeaders = headers.join(",")

  // üîç STEP 4: Convert records v·ªõi comprehensive extraction
  let totalExtractedValues = 0
  let totalEmptyValues = 0
  let extractionErrors = 0

  const csvRows = data.map((record, recordIndex) => {
    const values = [
      String(recordIndex + 1), // STT
      ...fieldNames.map((fieldName) => {
        const rawValue = record.fields[fieldName]

        try {
          const cleanValue = extractPlainTextFromField(rawValue, fieldName)

          if (!cleanValue || cleanValue.trim() === "") {
            totalEmptyValues++
            return ""
          }

          totalExtractedValues++

          // üî• PROPER CSV ESCAPING
          if (
            cleanValue.includes(",") ||
            cleanValue.includes('"') ||
            cleanValue.includes("\n") ||
            cleanValue.includes("\r")
          ) {
            return `"${cleanValue.replace(/"/g, '""')}"`
          }

          return cleanValue
        } catch (error) {
          extractionErrors++
          console.error(`‚ùå Extraction error for record ${recordIndex + 1}, field "${fieldName}":`, error)
          return `ERROR: ${error}`
        }
      }),
    ]

    return values.join(",")
  })

  const csvContent = [csvHeaders, ...csvRows].join("\n")

  // üîç STEP 5: Data integrity validation
  const originalJsonSize = JSON.stringify(data).length
  const csvSize = csvContent.length
  const compressionRatio = Math.round((1 - csvSize / originalJsonSize) * 100)

  const totalPossibleValues = data.length * fieldNames.length
  const dataIntegrityRate = ((totalExtractedValues / totalPossibleValues) * 100).toFixed(1)

  console.log(`‚úÖ ===== CSV CONVERSION COMPLETE =====`)
  console.log(`üìä Records: ${data.length}`)
  console.log(`üìã Fields: ${fieldNames.length}`)
  console.log(`üìÑ Total columns: ${headers.length}`)
  console.log(`üìÑ Original JSON: ${originalJsonSize} chars`)
  console.log(`üìÑ Final CSV: ${csvSize} chars`)
  console.log(`üéØ Compression: ${compressionRatio}% smaller`)
  console.log(`üéØ Estimated tokens: ${estimateTokens(csvContent)}`)
  console.log(``)
  console.log(`üîç DATA INTEGRITY REPORT:`)
  console.log(`  üìä Total possible values: ${totalPossibleValues}`)
  console.log(`  ‚úÖ Successfully extracted: ${totalExtractedValues}`)
  console.log(`  ‚ö™ Empty values: ${totalEmptyValues}`)
  console.log(`  ‚ùå Extraction errors: ${extractionErrors}`)
  console.log(`  üéØ Data integrity rate: ${dataIntegrityRate}%`)

  if (Number.parseFloat(dataIntegrityRate) < 70) {
    console.warn(`‚ö†Ô∏è LOW DATA INTEGRITY: Only ${dataIntegrityRate}% of data extracted successfully!`)
  } else {
    console.log(`‚úÖ GOOD DATA INTEGRITY: ${dataIntegrityRate}% extraction success rate`)
  }

  console.log(`===============================================`)

  return csvContent
}

// üî• ENHANCED: Data integrity validation function
const validateDataIntegrity = (
  originalData: Array<{ recordId: string; fields: Record<string, unknown> }>,
  csvContent: string,
): { isValid: boolean; report: string; issues: string[] } => {
  const issues: string[] = []

  try {
    const csvLines = csvContent.trim().split("\n")
    const headerLine = csvLines[0]
    const dataLines = csvLines.slice(1)

    // Check record count
    if (dataLines.length !== originalData.length) {
      issues.push(`Record count mismatch: Expected ${originalData.length}, got ${dataLines.length}`)
    }

    // Check field count
    const csvHeaders = headerLine.split(",")
    const originalFieldCount = new Set<string>()
    originalData.forEach((record) => {
      Object.keys(record.fields).forEach((field) => originalFieldCount.add(field))
    })

    const expectedFieldCount = originalFieldCount.size + 1 // +1 for STT column
    if (csvHeaders.length !== expectedFieldCount) {
      issues.push(`Field count mismatch: Expected ${expectedFieldCount}, got ${csvHeaders.length}`)
    }

    // Check for empty rows
    const emptyRows = dataLines.filter(
      (line) => line.trim() === "" || line.split(",").every((cell) => cell.trim() === ""),
    ).length
    if (emptyRows > 0) {
      issues.push(`Found ${emptyRows} completely empty rows`)
    }

    // Check data density
    const totalCells = dataLines.length * csvHeaders.length
    const emptyCells = dataLines.reduce((count, line) => {
      return count + line.split(",").filter((cell) => cell.trim() === "").length
    }, 0)

    const dataDensity = (((totalCells - emptyCells) / totalCells) * 100).toFixed(1)
    if (Number.parseFloat(dataDensity) < 50) {
      issues.push(`Low data density: Only ${dataDensity}% of cells contain data`)
    }

    const report = `
üìä Data Integrity Validation Report:
  ‚úÖ Records: ${dataLines.length}/${originalData.length}
  ‚úÖ Fields: ${csvHeaders.length}/${expectedFieldCount}
  ‚úÖ Data density: ${dataDensity}%
  ‚úÖ Empty rows: ${emptyRows}
  ${issues.length === 0 ? "‚úÖ All checks passed!" : `‚ö†Ô∏è ${issues.length} issues found`}
    `

    return {
      isValid: issues.length === 0,
      report: report,
      issues: issues,
    }
  } catch (error) {
    const errorMsg = `Validation error: ${error}`
    return {
      isValid: false,
      report: errorMsg,
      issues: [errorMsg],
    }
  }
}

// üî• NEW: Random API selection
const selectRandomWorkingAPI = async (): Promise<{ apiKey: string; apiIndex: number; details: any } | null> => {
  console.log(`üé≤ Selecting random working API from ${API_KEYS.length} available keys...`)

  const apiTestResults = []
  for (let i = 0; i < API_KEYS.length; i++) {
    console.log(`üß™ Testing API ${i + 1}...`)
    const testResult = await testSingleAPI(i)
    apiTestResults.push({ ...testResult, index: i })

    if (testResult.success) {
      console.log(`‚úÖ API ${i + 1} working`)
    } else {
      console.log(`‚ùå API ${i + 1} failed: ${testResult.details.error}`)
    }
  }

  const workingAPIs = apiTestResults.filter((result) => result.success)
  console.log(`üîë Found ${workingAPIs.length}/${API_KEYS.length} working APIs`)

  if (workingAPIs.length === 0) {
    console.log(`‚ùå No working APIs found`)
    return null
  }

  const randomIndex = Math.floor(Math.random() * workingAPIs.length)
  const selectedAPI = workingAPIs[randomIndex]
  const apiKey = API_KEYS[selectedAPI.index]

  console.log(
    `üéØ Randomly selected API ${selectedAPI.index + 1} (${randomIndex + 1}/${workingAPIs.length} working APIs)`,
  )
  console.log(`üîë Selected API preview: ${apiKey.substring(0, 10)}...${apiKey.substring(apiKey.length - 4)}`)

  return {
    apiKey: apiKey,
    apiIndex: selectedAPI.index,
    details: selectedAPI.details,
  }
}

// Test single API key v·ªõi Llama 4 Scout
const testSingleAPI = async (keyIndex: number): Promise<{ success: boolean; details: any }> => {
  const cacheKey = `test_${keyIndex}_${SINGLE_MODEL}`

  if (testResultsCache.has(cacheKey)) {
    console.log(`üîÑ Using cached test result for API ${keyIndex + 1}`)
    return {
      success: testResultsCache.get(cacheKey)!,
      details: { cached: true, keyIndex: keyIndex + 1 },
    }
  }

  try {
    const apiKey = API_KEYS[keyIndex]
    console.log(`üß™ Testing API ${keyIndex + 1} with ${SINGLE_MODEL}`)

    const groq = createGroqClient(apiKey)
    const startTime = Date.now()

    const testCompletion = await groq.chat.completions.create({
      model: SINGLE_MODEL,
      messages: [
        {
          role: "user",
          content: "Test: Return 'OK'",
        },
      ],
      temperature: 0.1,
      max_tokens: 10,
    })

    const responseTime = Date.now() - startTime
    const response = testCompletion?.choices?.[0]?.message?.content
    const success = !!response

    // Cache result
    testResultsCache.set(cacheKey, success)

    const details = {
      keyIndex: keyIndex + 1,
      status: success ? "success" : "failed",
      response: response,
      responseTime: responseTime,
      preview: `${apiKey.substring(0, 10)}...${apiKey.substring(apiKey.length - 4)}`,
      model: SINGLE_MODEL,
      error: success ? null : "No response content",
    }

    console.log(
      `${success ? "‚úÖ" : "‚ùå"} API ${keyIndex + 1} ${SINGLE_MODEL}: ${success ? "OK" : "FAILED"} (${responseTime}ms)`,
    )
    if (success) {
      console.log(`üîç Response: "${response}"`)
    }

    return { success, details }
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error)
    console.log(`‚ùå API ${keyIndex + 1} ${SINGLE_MODEL} failed: ${errorMsg}`)

    testResultsCache.set(cacheKey, false)

    const details = {
      keyIndex: keyIndex + 1,
      status: "failed",
      error: errorMsg,
      preview: `${API_KEYS[keyIndex].substring(0, 10)}...${API_KEYS[keyIndex].substring(API_KEYS[keyIndex].length - 4)}`,
      model: SINGLE_MODEL,
      response: null,
      responseTime: 0,
    }

    return { success: false, details }
  }
}

const createGroqClient = (apiKey: string): Groq => {
  return new Groq({
    apiKey: apiKey,
    dangerouslyAllowBrowser: true,
  })
}

// üî• ENHANCED: Single request analysis v·ªõi data integrity validation
const analyzeFullCSVWithRandomAPI = async (
  csvContent: string,
  tableName: string,
  recordCount: number,
  dataIntegrityReport: string,
): Promise<{ success: boolean; analysis: string; apiDetails: any; error?: string }> => {
  try {
    console.log(`\nüöÄ ===== ENHANCED SINGLE REQUEST ANALYSIS =====`)
    console.log(`üìä INPUT: ${recordCount} records`)
    console.log(`üìÑ CSV size: ${csvContent.length} characters`)
    console.log(`üéØ Estimated tokens: ${estimateTokens(csvContent)}`)

    const selectedAPI = await selectRandomWorkingAPI()

    if (!selectedAPI) {
      return {
        success: false,
        analysis: "‚ùå Kh√¥ng c√≥ API n√†o ho·∫°t ƒë·ªông",
        apiDetails: { error: "No working APIs" },
        error: "No working APIs available",
      }
    }

    console.log(`üéØ Using API ${selectedAPI.apiIndex + 1} for analysis`)

    const groq = createGroqClient(selectedAPI.apiKey)

    // üî• ENHANCED: Analysis prompt v·ªõi data integrity context
    const analysisPrompt = `Ph√¢n t√≠ch to√†n b·ªô d·ªØ li·ªáu CSV t·ª´ b·∫£ng "${tableName}" (${recordCount} records):

${dataIntegrityReport}

${csvContent}

Th·ª±c hi·ªán ph√¢n t√≠ch to√†n di·ªán v·ªõi focus v√†o data integrity:

1. **T·ªïng quan d·ªØ li·ªáu:**
   - S·ªë l∆∞·ª£ng records v√† fields th·ª±c t·∫ø
   - Ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu v√† completeness
   - C√°c field c√≥ gi√° tr·ªã v√† field tr·ªëng

2. **Th·ªëng k√™ chi ti·∫øt:**
   - Ph√¢n b·ªë theo c√°c tr∆∞·ªùng quan tr·ªçng
   - Gi√° tr·ªã ph·ªï bi·∫øn v√† unique values
   - Patterns v√† trends trong d·ªØ li·ªáu

3. **Data Quality Assessment:**
   - Fields n√†o c√≥ data ƒë·∫ßy ƒë·ªß nh·∫•t
   - Fields n√†o b·ªã thi·∫øu data nhi·ªÅu
   - Consistency c·ªßa d·ªØ li·ªáu

4. **Insights quan tr·ªçng:**
   - Ph√°t hi·ªán th√∫ v·ªã t·ª´ d·ªØ li·ªáu complete
   - M·ªëi quan h·ªá gi·ªØa c√°c tr∆∞·ªùng
   - Business insights v√† recommendations

5. **K·∫øt lu·∫≠n:**
   - T√≥m t·∫Øt findings ch√≠nh
   - Data reliability assessment
   - Actionable insights

L∆∞u √Ω: T·∫≠p trung v√†o d·ªØ li·ªáu th·ª±c t·∫ø c√≥ trong CSV, kh√¥ng ƒëo√°n m√≤ ho·∫∑c t·∫°o ra th√¥ng tin kh√¥ng c√≥.

Tr·∫£ l·ªùi chi ti·∫øt b·∫±ng ti·∫øng Vi·ªát v·ªõi format r√µ r√†ng:`

    const promptTokens = estimateTokens(analysisPrompt)
    console.log(`üì§ Sending enhanced analysis request: ${promptTokens} input tokens`)

    const startTime = Date.now()

    const completion = await groq.chat.completions.create({
      model: SINGLE_MODEL,
      messages: [{ role: "user", content: analysisPrompt }],
      temperature: 0.7,
      max_tokens: 4000,
    })

    const responseTime = Date.now() - startTime
    console.log(`üì• Response received (${responseTime}ms)`)

    if (!completion?.choices?.[0]?.message?.content) {
      const errorMsg = "Empty response from API"
      console.log(`‚ùå ${errorMsg}`)
      return {
        success: false,
        analysis: `‚ùå Kh√¥ng nh·∫≠n ƒë∆∞·ª£c ph·∫£n h·ªìi t·ª´ ${SINGLE_MODEL}`,
        apiDetails: selectedAPI.details,
        error: errorMsg,
      }
    }

    const analysis = completion.choices[0].message.content.trim()
    const outputTokens = estimateTokens(analysis)

    console.log(`üìä OUTPUT: ${outputTokens} tokens`)
    console.log(`‚ö° Total processing time: ${responseTime}ms`)
    console.log(`‚úÖ SUCCESS: Analyzed ${recordCount} records with enhanced data integrity`)
    console.log(`üìã Analysis preview: ${analysis.substring(0, 150)}...`)
    console.log(`===== END ENHANCED ANALYSIS =====\n`)

    return {
      success: true,
      analysis: analysis,
      apiDetails: {
        ...selectedAPI.details,
        responseTime: responseTime,
        inputTokens: promptTokens,
        outputTokens: outputTokens,
        totalTokens: promptTokens + outputTokens,
      },
    }
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error)
    console.error(`‚ùå Enhanced analysis failed: ${errorMsg}`)

    return {
      success: false,
      analysis: `‚ùå L·ªói ph√¢n t√≠ch v·ªõi ${SINGLE_MODEL}: ${errorMsg}`,
      apiDetails: { error: errorMsg },
      error: errorMsg,
    }
  }
}

// üî• UPDATED: Main pipeline v·ªõi enhanced data integrity
export const preprocessDataWithPipeline = async (
  data: any[],
  tableName: string,
): Promise<{ success: boolean; optimizedData: string; analysis: string; keyUsage: any }> => {
  try {
    console.log(`üöÄ Enhanced Single Request Pipeline v·ªõi ${data.length} records - Model: ${SINGLE_MODEL}`)

    if (!API_KEYS || API_KEYS.length === 0) {
      throw new Error("C·∫ßn √≠t nh·∫•t 1 API key")
    }

    // üî• B∆Ø·ªöC 1: Enhanced CSV conversion v·ªõi data integrity
    console.log(`üìä B∆Ø·ªöC 1: Enhanced CSV conversion v·ªõi data integrity validation...`)
    const fullCSV = convertToCSV(data)

    if (!fullCSV) {
      throw new Error("Kh√¥ng th·ªÉ t·∫°o CSV content")
    }

    // üî• B∆Ø·ªöC 2: Validate data integrity
    console.log(`üîç B∆Ø·ªöC 2: Validating data integrity...`)
    const integrityValidation = validateDataIntegrity(data, fullCSV)

    if (!integrityValidation.isValid) {
      console.warn(`‚ö†Ô∏è Data integrity issues detected:`)
      integrityValidation.issues.forEach((issue) => console.warn(`  - ${issue}`))
    }

    // üî• B∆Ø·ªöC 3: Enhanced analysis v·ªõi data integrity context
    console.log(`ü§ñ B∆Ø·ªöC 3: Enhanced analysis v·ªõi data integrity context...`)
    const analysisResult = await analyzeFullCSVWithRandomAPI(
      fullCSV,
      tableName,
      data.length,
      integrityValidation.report,
    )

    if (!analysisResult.success) {
      console.log(`‚ùå Analysis failed, using raw CSV`)
      return {
        success: true,
        optimizedData: fullCSV,
        analysis: analysisResult.analysis,
        keyUsage: {
          error: true,
          format: "Raw CSV",
          fallback: true,
          model: SINGLE_MODEL,
          strategy: "Enhanced Single Request",
          errorDetails: analysisResult.error,
          dataIntegrity: integrityValidation,
        },
      }
    }

    // üî• SUCCESS: Return enhanced results
    const keyUsage = {
      totalKeys: API_KEYS.length,
      usedAPI: analysisResult.apiDetails.keyIndex,
      selectedRandomly: true,
      totalRecords: data.length,
      processedRecords: data.length,
      dataLoss: 0,
      format: "Enhanced CSV",
      model: SINGLE_MODEL,
      strategy: "Enhanced Single Request with Data Integrity",
      responseTime: analysisResult.apiDetails.responseTime,
      inputTokens: analysisResult.apiDetails.inputTokens,
      outputTokens: analysisResult.apiDetails.outputTokens,
      totalTokens: analysisResult.apiDetails.totalTokens,
      apiPreview: analysisResult.apiDetails.preview,
      dataIntegrity: integrityValidation,
    }

    console.log(`‚úÖ Enhanced Single Request Pipeline Complete:`)
    console.log(`  üìä Records: ${data.length} (100% processed)`)
    console.log(`  üéØ API used: ${analysisResult.apiDetails.keyIndex}`)
    console.log(`  ‚ö° Time: ${analysisResult.apiDetails.responseTime}ms`)
    console.log(`  üé´ Tokens: ${analysisResult.apiDetails.totalTokens}`)
    console.log(`  üîç Data integrity: ${integrityValidation.isValid ? "‚úÖ Valid" : "‚ö†Ô∏è Issues detected"}`)

    return {
      success: true,
      optimizedData: fullCSV,
      analysis: analysisResult.analysis,
      keyUsage: keyUsage,
    }
  } catch (error) {
    console.error("‚ùå Enhanced Single Request Pipeline failed:", error)

    const rawCSV = convertToCSV(data)
    return {
      success: true,
      optimizedData: rawCSV,
      analysis: `‚ùå Pipeline error v·ªõi ${SINGLE_MODEL}: ${error}. S·ª≠ d·ª•ng raw CSV v·ªõi ${data.length} records.`,
      keyUsage: {
        error: true,
        format: "Raw CSV",
        model: SINGLE_MODEL,
        fallback: true,
        strategy: "Enhanced Single Request",
        dataIntegrity: { isValid: false, report: "Pipeline failed", issues: [String(error)] },
      },
    }
  }
}

// Rest of the functions remain the same...
export const answerQuestionWithOptimizedData = async (
  optimizedCSVData: string,
  tableName: string,
  question: string,
  originalRecordCount: number,
): Promise<string> => {
  try {
    console.log(`ü§î Tr·∫£ l·ªùi c√¢u h·ªèi v·ªõi enhanced CSV data (${originalRecordCount} records) - ${SINGLE_MODEL}`)

    const selectedAPI = await selectRandomWorkingAPI()

    if (!selectedAPI) {
      return `‚ùå Kh√¥ng c√≥ API n√†o ho·∫°t ƒë·ªông v·ªõi ${SINGLE_MODEL}`
    }

    console.log(`üéØ Using API ${selectedAPI.apiIndex + 1} for question answering`)

    const maxCSVLength = 6000
    const truncatedCSV =
      optimizedCSVData.length > maxCSVLength ? optimizedCSVData.substring(0, maxCSVLength) + "..." : optimizedCSVData

    const questionPrompt = `D·ªØ li·ªáu t·ª´ b·∫£ng "${tableName}" (${originalRecordCount} records) v·ªõi enhanced data integrity:

${truncatedCSV}

C√¢u h·ªèi: ${question}

Ph√¢n t√≠ch d·ªØ li·ªáu th·ª±c t·∫ø v√† tr·∫£ l·ªùi chi ti·∫øt b·∫±ng ti·∫øng Vi·ªát v·ªõi:
1. Tr·∫£ l·ªùi tr·ª±c ti·∫øp c√¢u h·ªèi d·ª±a tr√™n d·ªØ li·ªáu c√≥ s·∫µn
2. D·∫´n ch·ª©ng c·ª• th·ªÉ t·ª´ CSV data
3. Insights b·ªï sung n·∫øu c√≥
4. L∆∞u √Ω v·ªÅ data quality n·∫øu c·∫ßn

Ch·ªâ d·ª±a v√†o d·ªØ li·ªáu th·ª±c t·∫ø trong CSV, kh√¥ng ƒëo√°n m√≤:

Tr·∫£ l·ªùi:`

    const groq = createGroqClient(selectedAPI.apiKey)
    const startTime = Date.now()

    const completion = await groq.chat.completions.create({
      model: SINGLE_MODEL,
      messages: [{ role: "user", content: questionPrompt }],
      temperature: 0.7,
      max_tokens: 2000,
    })

    const responseTime = Date.now() - startTime

    if (!completion?.choices?.[0]?.message?.content) {
      throw new Error("No response content")
    }

    const answer = completion.choices[0].message.content
    console.log(`‚úÖ Question answered with enhanced data integrity (${responseTime}ms)`)

    return answer
  } catch (error) {
    console.error("‚ùå answerQuestionWithOptimizedData failed:", error)
    return `‚ùå L·ªói khi tr·∫£ l·ªùi c√¢u h·ªèi v·ªõi ${SINGLE_MODEL}: ${error}`
  }
}

// Export functions
export const analyzeDataWithParallelKeys = preprocessDataWithPipeline

export const answerQuestionWithData = async (
  data: any[],
  tableName: string,
  question: string,
  previousAnalysis?: string,
  optimizedData?: string,
): Promise<string> => {
  try {
    if (optimizedData && optimizedData.length > 0) {
      return await answerQuestionWithOptimizedData(optimizedData, tableName, question, data.length)
    } else {
      const quickCSV = convertToCSV(data.slice(0, 30))
      return await answerQuestionWithOptimizedData(quickCSV, tableName, question, data.length)
    }
  } catch (error) {
    console.error("‚ùå answerQuestionWithData failed:", error)
    return `‚ùå L·ªói khi tr·∫£ l·ªùi c√¢u h·ªèi: ${error}`
  }
}

export const testAllApiKeys = async (): Promise<{
  success: boolean
  message: string
  workingKeys: number
  totalKeys: number
  keyDetails: any[]
}> => {
  console.log(`üß™ Testing ${API_KEYS.length} API keys v·ªõi ${SINGLE_MODEL}...`)

  const testPromises = API_KEYS.map(async (apiKey, index) => {
    try {
      const groq = createGroqClient(apiKey)
      const startTime = Date.now()

      const testCompletion = await groq.chat.completions.create({
        model: SINGLE_MODEL,
        messages: [
          {
            role: "user",
            content: "Test: Return 'OK'",
          },
        ],
        temperature: 0.1,
        max_tokens: 10,
      })

      const responseTime = Date.now() - startTime
      const response = testCompletion?.choices?.[0]?.message?.content || "No response"
      console.log(`‚úÖ API ${index + 1}: OK (${responseTime}ms)`)

      return {
        keyIndex: index + 1,
        status: "success" as const,
        response: response,
        responseTime: responseTime,
        preview: `${apiKey.substring(0, 10)}...${apiKey.substring(apiKey.length - 4)}`,
        model: SINGLE_MODEL,
      }
    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error)
      console.log(`‚ùå API ${index + 1}: ${errorMsg}`)
      return {
        keyIndex: index + 1,
        status: "failed" as const,
        error: errorMsg,
        preview: `${apiKey.substring(0, 10)}...${apiKey.substring(apiKey.length - 4)}`,
        model: SINGLE_MODEL,
        responseTime: 0,
      }
    }
  })

  const results = await Promise.all(testPromises)
  const workingKeys = results.filter((r) => r.status === "success").length

  return {
    success: workingKeys > 0,
    message: `${workingKeys}/${API_KEYS.length} API keys ho·∫°t ƒë·ªông v·ªõi ${SINGLE_MODEL}`,
    workingKeys: workingKeys,
    totalKeys: API_KEYS.length,
    keyDetails: results,
  }
}

// Backward compatibility functions
export const askAI = async (context: string, question: string): Promise<string> => {
  return await answerQuestionWithData([], "Unknown", question)
}

export const askAIWithFullData = async (data: any[], tableName: string, question: string): Promise<string> => {
  return await answerQuestionWithData(data, tableName, question)
}

export const askAIWithRawData = async (data: any[], tableName: string, question: string): Promise<string> => {
  return await answerQuestionWithData(data, tableName, question)
}

export const testGroqAPI = async () => {
  const result = await testAllApiKeys()
  return {
    success: result.success,
    message: result.message,
    workingModel: SINGLE_MODEL,
    format: "Enhanced Single Request CSV",
  }
}

export const getAvailableModels = (): string[] => {
  return [SINGLE_MODEL]
}

export const getApiKeysInfo = () => {
  return {
    totalKeys: API_KEYS.length,
    keysPreview: API_KEYS.map(
      (key, index) => `API ${index + 1}: ${key.substring(0, 10)}...${key.substring(key.length - 4)} (${SINGLE_MODEL})`,
    ),
    format: "Enhanced Single Request CSV",
    model: SINGLE_MODEL,
  }
}

export const clearApiCache = () => {
  testResultsCache.clear()
  console.log("üîÑ Cache cleared")
}
