import { Groq } from "groq-sdk"

// Danh s√°ch API keys
const API_KEYS = [
  process.env.NEXT_PUBLIC_GROQ_API_KEY_1 || "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",
  process.env.NEXT_PUBLIC_GROQ_API_KEY_2 || "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",
  process.env.NEXT_PUBLIC_GROQ_API_KEY_3 || "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",
  process.env.NEXT_PUBLIC_GROQ_API_KEY_4 || "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",
  process.env.NEXT_PUBLIC_GROQ_API_KEY_5 || "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",
].filter((key) => key && !key.includes("account") && key.startsWith("gsk_"))

const AVAILABLE_MODELS = [
  "meta-llama/llama-guard-4-12b", // Ch·ªâ d√πng model n√†y
]

// Function ∆∞·ªõc t√≠nh s·ªë tokens (1 token ‚âà 4 characters)
const estimateTokens = (text: string): number => {
  return Math.ceil(text.length / 4)
}

// üî• NEW: CSV Conversion Functions
const convertToCSV = (data: Array<{ recordId: string; fields: Record<string, unknown> }>): string => {
  if (data.length === 0) return ""

  console.log(`üìä Converting ${data.length} records to CSV format...`)

  // Get all unique field names t·ª´ t·∫•t c·∫£ records
  const allFieldNames = new Set<string>()
  data.forEach((record) => {
    Object.keys(record.fields).forEach((fieldName) => {
      allFieldNames.add(fieldName)
    })
  })

  const fieldNames = Array.from(allFieldNames).sort()
  console.log(`üìã Found ${fieldNames.length} unique fields:`, fieldNames.slice(0, 5))

  // Create CSV headers
  const headers = ["recordId", ...fieldNames]
  const csvHeaders = headers.join(",")

  // Convert records to CSV rows
  const csvRows = data.map((record) => {
    const values = [
      record.recordId,
      ...fieldNames.map((fieldName) => {
        const value = record.fields[fieldName]
        if (value === null || value === undefined) return ""

        // Handle different data types
        if (typeof value === "object") {
          return JSON.stringify(value).replace(/"/g, '""')
        }

        // Escape quotes and handle strings
        return String(value).replace(/"/g, '""')
      }),
    ]

    // Wrap values in quotes to handle commas and special characters
    return values.map((v) => `"${v}"`).join(",")
  })

  const csvContent = [csvHeaders, ...csvRows].join("\n")

  const originalSize = JSON.stringify(data).length
  const csvSize = csvContent.length
  const compressionRatio = Math.round((csvSize / originalSize) * 100)

  console.log(`‚úÖ CSV Conversion Complete:`)
  console.log(`  üìä Records: ${data.length}`)
  console.log(`  üìã Fields: ${fieldNames.length}`)
  console.log(`  üìÑ JSON size: ${originalSize} chars`)
  console.log(`  üìÑ CSV size: ${csvSize} chars`)
  console.log(`  üìâ Compression: ${compressionRatio}% (${100 - compressionRatio}% reduction)`)
  console.log(`  üéØ Estimated tokens: ${estimateTokens(csvContent)} (vs ${estimateTokens(JSON.stringify(data))} JSON)`)

  return csvContent
}

// üî• NEW: CSV Validation Function
const validateCSV = (csvContent: string): { isValid: boolean; rowCount: number; error?: string } => {
  try {
    const lines = csvContent.trim().split("\n")
    if (lines.length < 2) {
      return { isValid: false, rowCount: 0, error: "CSV must have at least header and one data row" }
    }

    const headerCount = lines[0].split(",").length
    let validRows = 0

    for (let i = 1; i < lines.length; i++) {
      const rowCols = lines[i].split(",").length
      if (rowCols === headerCount) {
        validRows++
      }
    }

    return {
      isValid: validRows > 0,
      rowCount: validRows,
      error: validRows === 0 ? "No valid data rows found" : undefined,
    }
  } catch (error) {
    return {
      isValid: false,
      rowCount: 0,
      error: `CSV validation error: ${error}`,
    }
  }
}

// üî• UPDATED: Function t√≠nh t·ªïng tokens v√† chia ƒë·ªÅu cho 4 API v·ªõi CSV
const calculateTokenDistribution = (
  data: any[],
): {
  totalTokens: number
  tokensPerAPI: number
  chunksPerAPI: number[]
  distribution: any[][]
  csvSize: number
  jsonSize: number
  compressionRatio: number
} => {
  // Convert to CSV first ƒë·ªÉ t√≠nh to√°n ch√≠nh x√°c
  const csvContent = convertToCSV(data)
  const jsonContent = JSON.stringify(data, null, 1)

  const csvTokens = estimateTokens(csvContent)
  const jsonTokens = estimateTokens(jsonContent)
  const compressionRatio = Math.round((csvTokens / jsonTokens) * 100)

  const tokensPerAPI = Math.ceil(csvTokens / 4) // Chia ƒë·ªÅu cho 4 API ƒë·∫ßu

  console.log(`üìä ===== CSV TOKEN DISTRIBUTION CALCULATION =====`)
  console.log(`üéØ Total records: ${data.length}`)
  console.log(`üìÑ JSON size: ${jsonContent.length} chars (${jsonTokens} tokens)`)
  console.log(`üìÑ CSV size: ${csvContent.length} chars (${csvTokens} tokens)`)
  console.log(`üìâ CSV Compression: ${compressionRatio}% (${100 - compressionRatio}% token reduction)`)
  console.log(`üìä Tokens per API (4 APIs): ${tokensPerAPI}`)
  console.log(`‚ö° Model: meta-llama/llama-guard-4-12b`)

  // Chia data th√†nh 4 ph·∫ßn d·ª±a tr√™n record count (v√¨ CSV format ƒë·ªìng nh·∫•t h∆°n)
  const recordsPerAPI = Math.ceil(data.length / 4)
  const chunks: any[][] = []
  const chunksPerAPI: number[] = []

  for (let i = 0; i < 4; i++) {
    const startIndex = i * recordsPerAPI
    const endIndex = Math.min(startIndex + recordsPerAPI, data.length)
    const chunk = data.slice(startIndex, endIndex)

    if (chunk.length > 0) {
      const chunkCSV = convertToCSV(chunk)
      const chunkTokens = estimateTokens(chunkCSV)

      console.log(`üìä API ${i + 1} chunk: ${chunk.length} records, ${chunkTokens} tokens`)
      chunks.push(chunk)
      chunksPerAPI.push(chunk.length)
    }
  }

  console.log(`üìä FINAL CSV DISTRIBUTION:`)
  chunks.forEach((chunk, index) => {
    const chunkCSV = convertToCSV(chunk)
    const chunkTokens = estimateTokens(chunkCSV)
    console.log(`  API ${index + 1}: ${chunk.length} records, ${chunkTokens} tokens`)
  })
  console.log(`  API 5: T·ªïng h·ª£p v√† tr·∫£ l·ªùi c√¢u h·ªèi`)
  console.log(`===============================================`)

  return {
    totalTokens: csvTokens,
    tokensPerAPI,
    chunksPerAPI,
    distribution: chunks,
    csvSize: csvContent.length,
    jsonSize: jsonContent.length,
    compressionRatio,
  }
}

// Th√™m function test single chunk v·ªõi CSV
const testSingleChunkCSV = async (chunk: any[], keyIndex: number): Promise<boolean> => {
  try {
    const apiKey = API_KEYS[keyIndex]
    const csvContent = convertToCSV(chunk)
    const estimatedTokens = estimateTokens(csvContent)

    console.log(`üß™ Test CSV chunk: ${chunk.length} records, ~${estimatedTokens} tokens`)

    if (estimatedTokens > 15000) {
      console.log(`‚ö†Ô∏è CSV Chunk qu√° l·ªõn (${estimatedTokens} tokens), c·∫ßn chia nh·ªè h∆°n`)
      return false
    }

    const groq = createGroqClient(apiKey)

    // Test v·ªõi prompt ƒë∆°n gi·∫£n
    const testCompletion = await groq.chat.completions.create({
      model: "meta-llama/llama-guard-4-12b",
      messages: [
        {
          role: "user",
          content: "Test: Return 'CSV OK'",
        },
      ],
      temperature: 0.1,
      max_tokens: 10,
    })

    const response = testCompletion?.choices?.[0]?.message?.content
    console.log(`‚úÖ Key ${keyIndex + 1} CSV test OK: ${response}`)
    return true
  } catch (error) {
    console.log(`‚ùå Key ${keyIndex + 1} CSV test failed: ${error}`)
    return false
  }
}

const createGroqClient = (apiKey: string): Groq => {
  return new Groq({
    apiKey: apiKey,
    dangerouslyAllowBrowser: true,
  })
}

// üî• UPDATED: Helper function ƒë·ªÉ ph√¢n t√≠ch v·ªõi CSV format
const analyzeWithSingleKey = async (apiKey: string, keyIndex: number, prompt: string): Promise<string> => {
  try {
    const promptTokens = estimateTokens(prompt)
    console.log(`ü§ñ FINAL ANALYSIS v·ªõi API 5 (Key ${keyIndex + 1}):`)
    console.log(`  üéØ Analysis INPUT tokens: ${promptTokens}`)
    console.log(`  ‚ö° Model: meta-llama/llama-guard-4-12b`)
    console.log(`  üìä Format: CSV`)

    const groq = createGroqClient(apiKey)

    const startTime = Date.now()
    const completion = (await Promise.race([
      groq.chat.completions.create({
        model: "meta-llama/llama-guard-4-12b",
        messages: [
          {
            role: "user",
            content: prompt,
          },
        ],
        temperature: 0.7,
        max_tokens: 25000,
      }),
      new Promise((_, reject) => setTimeout(() => reject(new Error("Timeout 90s")), 90000)),
    ])) as any

    const responseTime = Date.now() - startTime

    if (!completion?.choices?.[0]?.message?.content) {
      console.log(`‚ö†Ô∏è No response content from meta-llama/llama-guard-4-12b`)
      throw new Error("No response content")
    }

    const analysis = completion.choices[0].message.content || "Kh√¥ng c√≥ ph√¢n t√≠ch"
    const outputTokens = estimateTokens(analysis)

    console.log(`‚úÖ CSV ANALYSIS COMPLETE:`)
    console.log(`  üéØ OUTPUT tokens: ${outputTokens}`)
    console.log(`  ‚ö° Processing time: ${responseTime}ms`)
    console.log(`  üìä Token efficiency: ${Math.round((outputTokens / promptTokens) * 100)}%`)

    return analysis
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error)
    console.error(`‚ùå CSV Analysis failed with meta-llama/llama-guard-4-12b: ${errorMsg}`)
    return `‚ùå Kh√¥ng th·ªÉ ph√¢n t√≠ch CSV v·ªõi meta-llama/llama-guard-4-12b: ${errorMsg}`
  }
}

// üî• UPDATED: Optimize data chunk v·ªõi CSV format
const optimizeDataChunk = async (
  apiKey: string,
  keyIndex: number,
  dataChunk: any[],
  chunkIndex: number,
  totalChunks: number,
  targetTokens: number,
): Promise<{ success: boolean; optimizedData: string; keyIndex: number; error?: string }> => {
  try {
    // Convert to CSV first
    const csvContent = convertToCSV(dataChunk)
    const estimatedTokens = estimateTokens(csvContent)

    // üî• UPDATED: Log chi ti·∫øt tokens v·ªõi CSV
    console.log(`\nüîß ===== API ${keyIndex + 1} - CSV CHUNK ${chunkIndex + 1}/${totalChunks} =====`)
    console.log(`üìä CSV TOKEN ANALYSIS:`)
    console.log(`  üéØ Target tokens for this API: ${targetTokens}`)
    console.log(`  üìù Actual records: ${dataChunk.length}`)
    console.log(`  üìÑ CSV characters: ${csvContent.length}`)
    console.log(`  üéØ INPUT TOKENS: ${estimatedTokens}`)
    console.log(`  üìà Token/record: ${Math.round(estimatedTokens / dataChunk.length)}`)
    console.log(`  üìä Target vs Actual: ${Math.round((estimatedTokens / targetTokens) * 100)}%`)

    // Validate CSV
    const csvValidation = validateCSV(csvContent)
    if (!csvValidation.isValid) {
      console.log(`‚ùå CSV VALIDATION FAILED: ${csvValidation.error}`)
      return {
        success: false,
        optimizedData: "",
        keyIndex: keyIndex,
        error: `CSV validation failed: ${csvValidation.error}`,
      }
    }

    console.log(`‚úÖ CSV Validation: ${csvValidation.rowCount} valid rows`)

    // Ki·ªÉm tra chunk size tr∆∞·ªõc khi g·ª≠i
    if (estimatedTokens > 15000) {
      console.log(`‚ùå CSV CHUNK QU√Å L·ªöN: ${estimatedTokens} tokens > 15000 limit`)
      return {
        success: false,
        optimizedData: "",
        keyIndex: keyIndex,
        error: `CSV chunk qu√° l·ªõn: ${estimatedTokens} tokens > 15000 limit`,
      }
    }

    const groq = createGroqClient(apiKey)

    // üî• UPDATED: Prompt cho CSV optimization
    const optimizePrompt = `Optimize this CSV data - remove empty rows, clean null values, maintain CSV format:

${csvContent}

Return clean, optimized CSV only (keep headers):`

    const promptTokens = estimateTokens(optimizePrompt)
    console.log(`üì§ SENDING CSV REQUEST:`)
    console.log(`  üéØ Total INPUT tokens: ${promptTokens} (prompt + CSV data)`)
    console.log(`  ‚ö° Model: meta-llama/llama-guard-4-12b`)
    console.log(`  üîÑ Max output tokens: 8000`)

    try {
      const startTime = Date.now()
      const completion = (await Promise.race([
        groq.chat.completions.create({
          model: "meta-llama/llama-guard-4-12b",
          messages: [{ role: "user", content: optimizePrompt }],
          temperature: 0.1,
          max_tokens: 8000,
        }),
        new Promise((_, reject) => setTimeout(() => reject(new Error("Timeout 60s")), 60000)),
      ])) as any

      const responseTime = Date.now() - startTime
      console.log(`üì• CSV RESPONSE RECEIVED (${responseTime}ms):`)

      if (!completion?.choices?.[0]?.message?.content) {
        throw new Error("Empty response from API")
      }

      const optimizedCSV = completion.choices[0].message.content.trim()
      const outputTokens = estimateTokens(optimizedCSV)
      const compressionRatio = Math.round((outputTokens / estimatedTokens) * 100)
      const tokensSaved = estimatedTokens - outputTokens

      console.log(`üìä CSV OUTPUT ANALYSIS:`)
      console.log(`  üìÑ Response chars: ${optimizedCSV.length}`)
      console.log(`  üéØ OUTPUT TOKENS: ${outputTokens}`)
      console.log(`  üìâ Compression: ${compressionRatio}% (${tokensSaved} tokens saved)`)
      console.log(`  ‚ö° Processing time: ${responseTime}ms`)
      console.log(`  üéØ Efficiency: ${Math.round((outputTokens / targetTokens) * 100)}% of target`)

      // Validate optimized CSV
      const optimizedValidation = validateCSV(optimizedCSV)
      if (optimizedValidation.isValid) {
        console.log(`‚úÖ CSV OPTIMIZATION SUCCESS:`)
        console.log(`  üìä Valid CSV with ${optimizedValidation.rowCount} rows`)
        console.log(`  üéØ TOKEN FLOW: ${estimatedTokens} ‚Üí ${outputTokens} (${compressionRatio}%)`)
        console.log(`===== END CSV API ${keyIndex + 1} =====\n`)

        return {
          success: true,
          optimizedData: optimizedCSV,
          keyIndex: keyIndex,
        }
      } else {
        console.log(`‚ùå CSV OPTIMIZATION VALIDATION FAILED:`)
        console.log(`  üîç Response preview: ${optimizedCSV.substring(0, 200)}...`)
        console.log(`  ‚ùå Error: ${optimizedValidation.error}`)
        throw new Error(`Invalid optimized CSV: ${optimizedValidation.error}`)
      }
    } catch (apiError) {
      const errorMsg = apiError instanceof Error ? apiError.message : String(apiError)
      console.log(`‚ùå CSV API ERROR:`)
      console.log(`  üö´ Error: ${errorMsg}`)
      console.log(`  üéØ INPUT tokens attempted: ${estimatedTokens}`)

      // Log chi ti·∫øt l·ªói API
      if (errorMsg.includes("rate_limit")) {
        console.log(`  ‚è∞ Rate limit exceeded for API ${keyIndex + 1}`)
      } else if (errorMsg.includes("quota")) {
        console.log(`  üí∞ Quota exceeded for API ${keyIndex + 1}`)
      } else if (errorMsg.includes("timeout")) {
        console.log(`  ‚è±Ô∏è Request timeout (60s) for API ${keyIndex + 1}`)
      } else {
        console.log(`  üîç Unknown error for API ${keyIndex + 1}`)
      }

      throw new Error(errorMsg)
    }
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error)
    console.error(`‚ùå CSV API ${keyIndex + 1} FAILED: ${errorMsg}`)

    return {
      success: false,
      optimizedData: "",
      keyIndex: keyIndex,
      error: errorMsg,
    }
  }
}

// Function debug optimize process v·ªõi CSV
const debugOptimizeProcess = async (chunk: any[], keyIndex: number): Promise<void> => {
  try {
    const csvContent = convertToCSV(chunk)
    const estimatedTokens = estimateTokens(csvContent)

    console.log(`üîç DEBUG CSV API ${keyIndex + 1}:`)
    console.log(`  - Records: ${chunk.length}`)
    console.log(`  - CSV Characters: ${csvContent.length}`)
    console.log(`  - Estimated tokens: ${estimatedTokens}`)
    console.log(`  - CSV preview:`, csvContent.substring(0, 200) + "...")

    // Test API key tr∆∞·ªõc
    const apiKey = API_KEYS[keyIndex]
    const groq = createGroqClient(apiKey)

    console.log(`üß™ Testing CSV API ${keyIndex + 1} v·ªõi simple request...`)
    const testResult = await groq.chat.completions.create({
      model: "meta-llama/llama-guard-4-12b",
      messages: [{ role: "user", content: "Say 'CSV test ok'" }],
      temperature: 0.1,
      max_tokens: 10,
    })

    console.log(`‚úÖ CSV API ${keyIndex + 1} test result:`, testResult?.choices?.[0]?.message?.content)
  } catch (error) {
    console.error(`‚ùå CSV DEBUG failed for API ${keyIndex + 1}:`, error)
  }
}

// üî• UPDATED: Function ch√≠nh v·ªõi CSV format
export const preprocessDataWithPipeline = async (
  data: any[],
  tableName: string,
): Promise<{ success: boolean; optimizedData: string; analysis: string; keyUsage: any }> => {
  try {
    console.log(`üöÄ B·∫Øt ƒë·∫ßu CSV Data Preprocessing Pipeline v·ªõi ${data.length} records`)

    if (!API_KEYS || API_KEYS.length < 5) {
      throw new Error("C·∫ßn √≠t nh·∫•t 5 API keys (4 cho optimize + 1 cho analysis)")
    }

    // üî• B∆Ø·ªöC 1: T√≠nh to√°n CSV token distribution
    console.log(`üìä B∆Ø·ªöC 1: T√≠nh to√°n CSV token distribution...`)
    const tokenDistribution = calculateTokenDistribution(data)

    if (tokenDistribution.distribution.length === 0) {
      throw new Error("Kh√¥ng th·ªÉ chia d·ªØ li·ªáu th√†nh chunks")
    }

    console.log(`üìä CSV vs JSON Comparison:`)
    console.log(`  üìÑ JSON: ${tokenDistribution.jsonSize} chars`)
    console.log(`  üìÑ CSV: ${tokenDistribution.csvSize} chars`)
    console.log(
      `  üìâ Compression: ${tokenDistribution.compressionRatio}% (${100 - tokenDistribution.compressionRatio}% reduction)`,
    )

    // Test API keys tr∆∞·ªõc v·ªõi CSV format
    console.log(`üß™ Test 4 API keys ƒë·∫ßu cho CSV optimize...`)
    const keyTests = await Promise.all(API_KEYS.slice(0, 4).map((key, index) => testSingleChunkCSV([data[0]], index)))
    const workingKeys = keyTests.filter(Boolean).length
    console.log(`üîë ${workingKeys}/4 CSV optimize APIs ho·∫°t ƒë·ªông`)

    if (workingKeys === 0) {
      throw new Error("Kh√¥ng c√≥ API keys n√†o ho·∫°t ƒë·ªông cho CSV optimize")
    }

    // Test API th·ª© 5 cho analysis
    console.log(`üß™ Test API 5 cho CSV analysis...`)
    const analysisKeyTest = await testSingleChunkCSV([data[0]], 4)
    if (!analysisKeyTest) {
      console.log(`‚ö†Ô∏è API 5 kh√¥ng ho·∫°t ƒë·ªông, s·∫Ω d√πng API 1 cho analysis`)
    }

    // B∆Ø·ªöC 2: Optimize t·ª´ng chunk v·ªõi CSV format
    console.log(`‚è≥ B∆Ø·ªöC 2: CSV Optimize ${tokenDistribution.distribution.length} chunks v·ªõi 4 APIs...`)

    const optimizeResults = []

    // X·ª≠ l√Ω t·ª´ng chunk v·ªõi API t∆∞∆°ng ·ª©ng
    for (let i = 0; i < Math.min(4, tokenDistribution.distribution.length); i++) {
      const chunk = tokenDistribution.distribution[i]
      const keyIndex = i // API 1,2,3,4

      console.log(`üîß X·ª≠ l√Ω CSV chunk ${i + 1} v·ªõi API ${keyIndex + 1}`)

      // Debug tr∆∞·ªõc khi optimize
      await debugOptimizeProcess(chunk, keyIndex)

      let result = null
      let retryCount = 0
      const maxRetries = 2

      // Retry mechanism
      while (retryCount <= maxRetries && (!result || !result.success)) {
        try {
          if (retryCount > 0) {
            console.log(`üîÑ CSV Retry ${retryCount}/${maxRetries} cho API ${keyIndex + 1}`)
            await new Promise((resolve) => setTimeout(resolve, 3000)) // Wait 3s
          }

          result = await optimizeDataChunk(
            API_KEYS[keyIndex],
            keyIndex,
            chunk,
            i,
            tokenDistribution.distribution.length,
            tokenDistribution.tokensPerAPI,
          )

          if (result && result.success) {
            console.log(`‚úÖ CSV API ${keyIndex + 1}: Th√†nh c√¥ng sau ${retryCount} retries`)
            break
          } else {
            console.log(
              `‚ùå CSV API ${keyIndex + 1}: Th·∫•t b·∫°i l·∫ßn ${retryCount + 1} - ${result?.error || "Unknown error"}`,
            )
          }
        } catch (error) {
          console.log(`‚ùå CSV API ${keyIndex + 1}: Exception l·∫ßn ${retryCount + 1} - ${error}`)
          result = {
            success: false,
            optimizedData: "",
            keyIndex: keyIndex,
            error: String(error),
          }
        }

        retryCount++
      }

      // ƒê·∫£m b·∫£o result kh√¥ng null tr∆∞·ªõc khi push
      if (result) {
        optimizeResults.push(result)
      } else {
        optimizeResults.push({
          success: false,
          optimizedData: "",
          keyIndex: keyIndex,
          error: "No result after retries",
        })
      }

      // Delay gi·ªØa c√°c API calls
      if (i < tokenDistribution.distribution.length - 1) {
        await new Promise((resolve) => setTimeout(resolve, 1000))
      }
    }

    // Debug chi ti·∫øt k·∫øt qu·∫£
    console.log(`üîç DEBUG: CSV Optimize results details:`)
    optimizeResults.forEach((result, index) => {
      if (result.success) {
        console.log(`‚úÖ CSV API ${index + 1}: Success`)
      } else {
        console.log(`‚ùå CSV API ${index + 1}: Failed - ${result.error}`)
      }
    })

    // Ki·ªÉm tra k·∫øt qu·∫£ optimize
    const successfulOptimizes = optimizeResults.filter((r) => r && r.success)
    const failedOptimizes = optimizeResults.filter((r) => r && !r.success)

    console.log(`üìä CSV Optimize results: ${successfulOptimizes.length}/4 APIs th√†nh c√¥ng`)

    // N·∫øu t·∫•t c·∫£ th·∫•t b·∫°i, th·ª≠ fallback v·ªõi raw CSV
    if (successfulOptimizes.length === 0) {
      console.log(`üîÑ CSV FALLBACK: T·∫•t c·∫£ optimize th·∫•t b·∫°i, s·ª≠ d·ª•ng raw CSV data`)

      const rawCSV = convertToCSV(data.slice(0, 50)) // L·∫•y 50 records ƒë·∫ßu

      const keyUsage = {
        totalKeys: API_KEYS.length,
        optimizeKeys: 0,
        analysisKey: 1,
        failedKeys: 4,
        successRate: "0%",
        chunks: tokenDistribution.distribution.length,
        successfulChunks: 0,
        finalDataSize: rawCSV.length,
        fallback: true,
        tokenDistribution: tokenDistribution,
        format: "CSV",
        compressionRatio: tokenDistribution.compressionRatio,
      }

      return {
        success: true,
        optimizedData: rawCSV,
        analysis: `‚ö†Ô∏è Kh√¥ng th·ªÉ optimize CSV v·ªõi 4 APIs, s·ª≠ d·ª•ng ${Math.min(50, data.length)} records ƒë·∫ßu ti√™n t·ª´ t·ªïng ${data.length} records trong CSV format.`,
        keyUsage: keyUsage,
      }
    }

    // B∆Ø·ªöC 3: G·ªôp CSV data ƒë√£ optimize
    console.log(`üìä B∆Ø·ªöC 3: G·ªôp ${successfulOptimizes.length} CSV chunks optimize`)

    let combinedCSVData = ""
    let headers = ""
    const allRows: string[] = []
    let validChunks = 0

    successfulOptimizes.forEach((result, index) => {
      try {
        const csvLines = result.optimizedData.trim().split("\n")
        if (csvLines.length < 2) return // Skip if no data

        if (validChunks === 0) {
          // First chunk - keep headers
          headers = csvLines[0]
          allRows.push(...csvLines.slice(1))
        } else {
          // Subsequent chunks - skip headers, add data rows
          allRows.push(...csvLines.slice(1))
        }
        validChunks++
      } catch (parseError) {
        console.warn(`‚ö†Ô∏è Kh√¥ng th·ªÉ parse CSV result t·ª´ API ${result.keyIndex + 1}:`, parseError)
      }
    })

    combinedCSVData = headers + "\n" + allRows.join("\n")

    const finalTokens = estimateTokens(combinedCSVData)
    console.log(`üìä B∆Ø·ªöC 3: ƒê√£ g·ªôp ${validChunks} CSV chunks optimize`)
    console.log(`  üìÑ Final CSV: ${combinedCSVData.length} characters`)
    console.log(`  üéØ Final tokens: ${finalTokens}`)
    console.log(`  üìâ Total compression: ${Math.round((finalTokens / tokenDistribution.totalTokens) * 100)}%`)

    // B∆Ø·ªöC 4: Ph√¢n t√≠ch t·ªïng h·ª£p v·ªõi CSV format
    const analysisKeyIndex = 4 // API 5
    const analysisApiKey = API_KEYS[analysisKeyIndex]

    if (!analysisApiKey) {
      throw new Error("Kh√¥ng c√≥ API 5 cho ph√¢n t√≠ch cu·ªëi")
    }

    console.log(`ü§ñ B∆Ø·ªöC 4: Ph√¢n t√≠ch t·ªïng h·ª£p CSV v·ªõi API 5`)

    const analysisPrompt = `B·∫°n l√† m·ªôt AI analyst chuy√™n nghi·ªáp. D∆∞·ªõi ƒë√¢y l√† d·ªØ li·ªáu t·ª´ b·∫£ng "${tableName}" trong CSV format ƒë√£ ƒë∆∞·ª£c optimize b·ªüi 4 APIs (${data.length} records g·ªëc, ${validChunks}/4 APIs th√†nh c√¥ng):

${combinedCSVData}

CSV Token Distribution Summary:
- Total original tokens: ${tokenDistribution.totalTokens}
- Tokens per API: ${tokenDistribution.tokensPerAPI}
- Final optimized tokens: ${finalTokens}
- CSV compression ratio: ${tokenDistribution.compressionRatio}% (${100 - tokenDistribution.compressionRatio}% token reduction vs JSON)

H√£y ph√¢n t√≠ch chi ti·∫øt d·ªØ li·ªáu CSV n√†y:
1. üìä T·ªïng quan v·ªÅ d·ªØ li·ªáu v√† c·∫•u tr√∫c CSV
2. üìà Th·ªëng k√™ quan tr·ªçng t·ª´ c√°c c·ªôt  
3. üîç Patterns v√† insights t·ª´ d·ªØ li·ªáu
4. üí° Nh·∫≠n x√©t v√† ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu

Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, chi ti·∫øt v√† c√≥ c·∫•u tr√∫c.`

    const finalAnalysis = await analyzeWithSingleKey(analysisApiKey, analysisKeyIndex, analysisPrompt)

    const keyUsage = {
      totalKeys: API_KEYS.length,
      optimizeKeys: successfulOptimizes.length,
      analysisKey: 1,
      failedKeys: failedOptimizes.length,
      successRate: `${Math.round((successfulOptimizes.length / 4) * 100)}%`,
      chunks: tokenDistribution.distribution.length,
      successfulChunks: validChunks,
      finalDataSize: combinedCSVData.length,
      tokenDistribution: tokenDistribution,
      finalTokens: finalTokens,
      compressionRatio: `${Math.round((finalTokens / tokenDistribution.totalTokens) * 100)}%`,
      format: "CSV",
      csvCompressionVsJson: `${tokenDistribution.compressionRatio}%`,
    }

    return {
      success: true,
      optimizedData: combinedCSVData,
      analysis: finalAnalysis,
      keyUsage: keyUsage,
    }
  } catch (error) {
    console.error("‚ùå CSV Data Preprocessing Pipeline failed:", error)
    return {
      success: false,
      optimizedData: "",
      analysis: `‚ùå L·ªói CSV preprocessing pipeline: ${error}`,
      keyUsage: { error: true, format: "CSV" },
    }
  }
}

// üî• UPDATED: Function tr·∫£ l·ªùi c√¢u h·ªèi v·ªõi CSV data
export const answerQuestionWithOptimizedData = async (
  optimizedCSVData: string,
  tableName: string,
  question: string,
  originalRecordCount: number,
): Promise<string> => {
  try {
    console.log(`ü§î Tr·∫£ l·ªùi c√¢u h·ªèi v·ªõi optimized CSV data (${originalRecordCount} records)`)

    // S·ª≠ d·ª•ng API 5 ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi
    const questionKeyIndex = 4 // API 5
    const questionApiKey = API_KEYS[questionKeyIndex]

    if (!questionApiKey) {
      throw new Error("Kh√¥ng c√≥ API 5 ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi")
    }

    const questionPrompt = `B·∫°n l√† m·ªôt AI assistant th√¥ng minh. D∆∞·ªõi ƒë√¢y l√† TO√ÄN B·ªò d·ªØ li·ªáu t·ª´ b·∫£ng "${tableName}" trong CSV format (${originalRecordCount} records ƒë√£ ƒë∆∞·ª£c optimize b·ªüi 4 APIs):

${optimizedCSVData}

ƒê√¢y l√† d·ªØ li·ªáu HO√ÄN CH·ªàNH t·ª´ ${originalRecordCount} b·∫£n ghi trong CSV format. H√£y d·ª±a v√†o d·ªØ li·ªáu CSV n√†y ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch ch√≠nh x√°c v√† chi ti·∫øt.

C√¢u h·ªèi: ${question}

H∆∞·ªõng d·∫´n ph√¢n t√≠ch CSV:
- D√≤ng ƒë·∫ßu ti√™n l√† headers (t√™n c·ªôt)
- C√°c d√≤ng ti·∫øp theo l√† d·ªØ li·ªáu
- H√£y ph√¢n t√≠ch theo c·ªôt v√† t√¨m patterns
- ƒê∆∞a ra s·ªë li·ªáu c·ª• th·ªÉ v√† insights

Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát:`

    return await analyzeWithSingleKey(questionApiKey, questionKeyIndex, questionPrompt)
  } catch (error) {
    console.error("‚ùå answerQuestionWithOptimizedData failed:", error)
    return `‚ùå L·ªói khi tr·∫£ l·ªùi c√¢u h·ªèi v·ªõi CSV: ${error}`
  }
}

// Export function ch√≠nh thay th·∫ø analyzeDataWithParallelKeys
export const analyzeDataWithParallelKeys = preprocessDataWithPipeline

// üî• UPDATED: Function tr·∫£ l·ªùi c√¢u h·ªèi - s·ª≠ d·ª•ng CSV optimized data
export const answerQuestionWithData = async (
  data: any[],
  tableName: string,
  question: string,
  previousAnalysis?: string,
  optimizedData?: string,
): Promise<string> => {
  try {
    if (optimizedData && optimizedData.length > 0) {
      // N·∫øu c√≥ optimized data (CSV format), s·ª≠ d·ª•ng n√≥
      return await answerQuestionWithOptimizedData(optimizedData, tableName, question, data.length)
    } else {
      // Fallback: t·∫°o CSV optimized data nhanh
      const quickCSV = convertToCSV(data.slice(0, 30)) // 30 records ƒë·∫ßu
      return await answerQuestionWithOptimizedData(quickCSV, tableName, question, data.length)
    }
  } catch (error) {
    console.error("‚ùå answerQuestionWithData failed:", error)
    return `‚ùå L·ªói khi tr·∫£ l·ªùi c√¢u h·ªèi: ${error}`
  }
}

// üî• UPDATED: Test functions v·ªõi CSV support
export const testAllApiKeys = async (): Promise<{
  success: boolean
  message: string
  workingKeys: number
  totalKeys: number
  keyDetails: any[]
}> => {
  console.log(`üß™ Testing ${API_KEYS.length} API keys v·ªõi CSV format...`)

  const testPromises = API_KEYS.map(async (apiKey, index) => {
    try {
      const groq = createGroqClient(apiKey)

      const testCompletion = await groq.chat.completions.create({
        model: "meta-llama/llama-guard-4-12b",
        messages: [
          {
            role: "user",
            content: "Test CSV: Return 'CSV OK'",
          },
        ],
        temperature: 0.1,
        max_tokens: 50,
      })

      const response = testCompletion?.choices?.[0]?.message?.content || "No response"
      console.log(`‚úÖ CSV API ${index + 1}: OK`)

      return {
        keyIndex: index + 1,
        status: "success" as const,
        response: response,
        preview: `${apiKey.substring(0, 10)}...${apiKey.substring(apiKey.length - 4)}`,
        role: index < 4 ? "CSV optimize" : "CSV analysis",
      }
    } catch (error) {
      console.log(`‚ùå CSV API ${index + 1}: ${error}`)
      return {
        keyIndex: index + 1,
        status: "failed" as const,
        error: error instanceof Error ? error.message : String(error),
        preview: `${apiKey.substring(0, 10)}...${apiKey.substring(apiKey.length - 4)}`,
        role: index < 4 ? "CSV optimize" : "CSV analysis",
      }
    }
  })

  const results = await Promise.all(testPromises)
  const workingKeys = results.filter((r) => r.status === "success").length

  return {
    success: workingKeys > 0,
    message: `${workingKeys}/${API_KEYS.length} API keys ho·∫°t ƒë·ªông v·ªõi CSV format (4 optimize + 1 analysis)`,
    workingKeys: workingKeys,
    totalKeys: API_KEYS.length,
    keyDetails: results,
  }
}

// Backward compatibility functions
export const askAI = async (context: string, question: string): Promise<string> => {
  return await answerQuestionWithData([], "Unknown", question)
}

export const askAIWithFullData = async (data: any[], tableName: string, question: string): Promise<string> => {
  return await answerQuestionWithData(data, tableName, question)
}

export const askAIWithRawData = async (data: any[], tableName: string, question: string): Promise<string> => {
  return await answerQuestionWithData(data, tableName, question)
}

export const testGroqAPI = async () => {
  const result = await testAllApiKeys()
  return {
    success: result.success,
    message: result.message,
    workingModel: "meta-llama/llama-guard-4-12b",
    format: "CSV",
  }
}

export const getAvailableModels = (): string[] => {
  return AVAILABLE_MODELS
}

export const getApiKeysInfo = () => {
  return {
    totalKeys: API_KEYS.length,
    keysPreview: API_KEYS.map(
      (key, index) =>
        `API ${index + 1}: ${key.substring(0, 10)}...${key.substring(key.length - 4)} (${index < 4 ? "CSV optimize" : "CSV analysis"})`,
    ),
    format: "CSV",
  }
}
