import { Groq } from "groq-sdk"

// Danh sÃ¡ch API keys
const API_KEYS = [
  process.env.NEXT_PUBLIC_GROQ_API_KEY_1 || "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",
  process.env.NEXT_PUBLIC_GROQ_API_KEY_2 || "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",
  process.env.NEXT_PUBLIC_GROQ_API_KEY_3 || "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",
  process.env.NEXT_PUBLIC_GROQ_API_KEY_4 || "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",
  process.env.NEXT_PUBLIC_GROQ_API_KEY_5 || "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",
].filter((key) => key && !key.includes("account") && key.startsWith("gsk_"))

// ğŸ”¥ FIXED: Sá»­ dá»¥ng chÃ­nh xÃ¡c compound-beta models
const AVAILABLE_MODELS = [
  "compound-beta", // Model chÃ­nh user muá»‘n dÃ¹ng
  "compound-beta-mini", // Model backup user muá»‘n dÃ¹ng
  "llama-3.1-8b-instant", // Fallback náº¿u compound models fail
]

// ğŸ”¥ FIXED: Separate caches for different data types
const apiCallCache = new Map<string, any>()
const testResultsCache = new Map<string, boolean>() // Boolean results only
const detailedTestCache = new Map<string, any>() // Detailed test results

// Function Æ°á»›c tÃ­nh sá»‘ tokens (1 token â‰ˆ 4 characters)
const estimateTokens = (text: string): number => {
  return Math.ceil(text.length / 4)
}

// ğŸ”¥ NEW: Debug function Ä‘á»ƒ kiá»ƒm tra model thá»±c sá»± Ä‘Æ°á»£c gá»i
const debugModelCall = async (apiKey: string, modelName: string): Promise<void> => {
  try {
    console.log(`ğŸ” DEBUG: Testing model "${modelName}" vá»›i API key ${apiKey.substring(0, 10)}...`)

    const groq = createGroqClient(apiKey)

    const testCompletion = await groq.chat.completions.create({
      model: modelName,
      messages: [
        {
          role: "user",
          content: "What model are you? Return only the model name.",
        },
      ],
      temperature: 0.1,
      max_tokens: 50,
    })

    const response = testCompletion?.choices?.[0]?.message?.content
    console.log(`ğŸ” DEBUG: Requested model: "${modelName}"`)
    console.log(`ğŸ” DEBUG: Response: "${response}"`)
    console.log(`ğŸ” DEBUG: Full completion object:`, JSON.stringify(testCompletion, null, 2))
  } catch (error) {
    console.error(`ğŸ” DEBUG: Model "${modelName}" failed:`, error)
  }
}

// ğŸ”¥ NEW: Function test táº¥t cáº£ models Ä‘á»ƒ tÃ¬m model nÃ o hoáº¡t Ä‘á»™ng
const testAvailableModels = async (): Promise<string[]> => {
  const modelsToTest = [
    "compound-beta",
    "compound-beta-mini",
    "llama-3.1-70b-versatile",
    "llama-3.1-8b-instant",
    "mixtral-8x7b-32768",
  ]

  const workingModels: string[] = []

  console.log(`ğŸ§ª Testing ${modelsToTest.length} models...`)

  for (const modelName of modelsToTest) {
    try {
      const groq = createGroqClient(API_KEYS[0]) // Test vá»›i key Ä‘áº§u tiÃªn

      console.log(`ğŸ§ª Testing model: ${modelName}`)

      const testCompletion = await groq.chat.completions.create({
        model: modelName,
        messages: [
          {
            role: "user",
            content: "Test: Return 'OK'",
          },
        ],
        temperature: 0.1,
        max_tokens: 5,
      })

      const response = testCompletion?.choices?.[0]?.message?.content
      if (response) {
        console.log(`âœ… Model "${modelName}" works: ${response}`)
        workingModels.push(modelName)

        // Debug thÃªm Ä‘á»ƒ xem model thá»±c sá»±
        await debugModelCall(API_KEYS[0], modelName)
      } else {
        console.log(`âŒ Model "${modelName}" no response`)
      }

      // Delay giá»¯a cÃ¡c test
      await new Promise((resolve) => setTimeout(resolve, 1000))
    } catch (error) {
      console.error(`âŒ Model "${modelName}" failed:`, error)
    }
  }

  console.log(`âœ… Working models: ${workingModels.join(", ")}`)
  return workingModels
}

// ğŸ”¥ NEW: CSV Conversion Functions
const convertToCSV = (data: Array<{ recordId: string; fields: Record<string, unknown> }>): string => {
  if (data.length === 0) return ""

  console.log(`ğŸ“Š Converting ${data.length} records to CSV format...`)

  // Get all unique field names tá»« táº¥t cáº£ records
  const allFieldNames = new Set<string>()
  data.forEach((record) => {
    Object.keys(record.fields).forEach((fieldName) => {
      allFieldNames.add(fieldName)
    })
  })

  const fieldNames = Array.from(allFieldNames).sort()
  console.log(`ğŸ“‹ Found ${fieldNames.length} unique fields:`, fieldNames.slice(0, 5))

  // Create CSV headers
  const headers = ["recordId", ...fieldNames]
  const csvHeaders = headers.join(",")

  // Convert records to CSV rows
  const csvRows = data.map((record) => {
    const values = [
      record.recordId,
      ...fieldNames.map((fieldName) => {
        const value = record.fields[fieldName]
        if (value === null || value === undefined) return ""

        // Handle different data types
        if (typeof value === "object") {
          return JSON.stringify(value).replace(/"/g, '""')
        }

        // Escape quotes and handle strings
        return String(value).replace(/"/g, '""')
      }),
    ]

    // Wrap values in quotes to handle commas and special characters
    return values.map((v) => `"${v}"`).join(",")
  })

  const csvContent = [csvHeaders, ...csvRows].join("\n")

  const originalSize = JSON.stringify(data).length
  const csvSize = csvContent.length
  const compressionRatio = Math.round((csvSize / originalSize) * 100)

  console.log(`âœ… CSV Conversion Complete:`)
  console.log(`  ğŸ“Š Records: ${data.length}`)
  console.log(`  ğŸ“‹ Fields: ${fieldNames.length}`)
  console.log(`  ğŸ“„ JSON size: ${originalSize} chars`)
  console.log(`  ğŸ“„ CSV size: ${csvSize} chars`)
  console.log(`  ğŸ“‰ Compression: ${compressionRatio}% (${100 - compressionRatio}% reduction)`)
  console.log(`  ğŸ¯ Estimated tokens: ${estimateTokens(csvContent)} (vs ${estimateTokens(JSON.stringify(data))} JSON)`)

  return csvContent
}

// ğŸ”¥ NEW: CSV Validation Function
const validateCSV = (csvContent: string): { isValid: boolean; rowCount: number; error?: string } => {
  try {
    const lines = csvContent.trim().split("\n")
    if (lines.length < 2) {
      return { isValid: false, rowCount: 0, error: "CSV must have at least header and one data row" }
    }

    const headerCount = lines[0].split(",").length
    let validRows = 0

    for (let i = 1; i < lines.length; i++) {
      const rowCols = lines[i].split(",").length
      if (rowCols === headerCount) {
        validRows++
      }
    }

    return {
      isValid: validRows > 0,
      rowCount: validRows,
      error: validRows === 0 ? "No valid data rows found" : undefined,
    }
  } catch (error) {
    return {
      isValid: false,
      rowCount: 0,
      error: `CSV validation error: ${error}`,
    }
  }
}

// ğŸ”¥ UPDATED: Function tÃ­nh tá»•ng tokens vÃ  chia Ä‘á»u cho 4 API vá»›i CSV
const calculateTokenDistribution = (
  data: any[],
): {
  totalTokens: number
  tokensPerAPI: number
  chunksPerAPI: number[]
  distribution: any[][]
  csvSize: number
  jsonSize: number
  compressionRatio: number
} => {
  // Convert to CSV first Ä‘á»ƒ tÃ­nh toÃ¡n chÃ­nh xÃ¡c
  const csvContent = convertToCSV(data)
  const jsonContent = JSON.stringify(data, null, 1)

  const csvTokens = estimateTokens(csvContent)
  const jsonTokens = estimateTokens(jsonContent)
  const compressionRatio = Math.round((csvTokens / jsonTokens) * 100)

  const tokensPerAPI = Math.ceil(csvTokens / 4) // Chia Ä‘á»u cho 4 API Ä‘áº§u

  console.log(`ğŸ“Š ===== CSV TOKEN DISTRIBUTION CALCULATION =====`)
  console.log(`ğŸ¯ Total records: ${data.length}`)
  console.log(`ğŸ“„ JSON size: ${jsonContent.length} chars (${jsonTokens} tokens)`)
  console.log(`ğŸ“„ CSV size: ${csvContent.length} chars (${csvTokens} tokens)`)
  console.log(`ğŸ“‰ CSV Compression: ${compressionRatio}% (${100 - compressionRatio}% token reduction)`)
  console.log(`ğŸ“Š Tokens per API (4 APIs): ${tokensPerAPI}`)
  console.log(`âš¡ Target Model: compound-beta`)

  // Chia data thÃ nh 4 pháº§n dá»±a trÃªn record count (vÃ¬ CSV format Ä‘á»“ng nháº¥t hÆ¡n)
  const recordsPerAPI = Math.min(Math.ceil(data.length / 4), 15) // TÄƒng lÃªn 15 records per API
  const chunks: any[][] = []
  const chunksPerAPI: number[] = []

  for (let i = 0; i < 4; i++) {
    const startIndex = i * recordsPerAPI
    const endIndex = Math.min(startIndex + recordsPerAPI, data.length)
    const chunk = data.slice(startIndex, endIndex)

    if (chunk.length > 0) {
      const chunkCSV = convertToCSV(chunk)
      const chunkTokens = estimateTokens(chunkCSV)

      console.log(`ğŸ“Š API ${i + 1} chunk: ${chunk.length} records, ${chunkTokens} tokens`)
      chunks.push(chunk)
      chunksPerAPI.push(chunk.length)
    }
  }

  console.log(`ğŸ“Š FINAL CSV DISTRIBUTION:`)
  chunks.forEach((chunk, index) => {
    const chunkCSV = convertToCSV(chunk)
    const chunkTokens = estimateTokens(chunkCSV)
    console.log(`  API ${index + 1}: ${chunk.length} records, ${chunkTokens} tokens`)
  })
  console.log(`  API 5: Tá»•ng há»£p vÃ  tráº£ lá»i cÃ¢u há»i`)
  console.log(`===============================================`)

  return {
    totalTokens: csvTokens,
    tokensPerAPI,
    chunksPerAPI,
    distribution: chunks,
    csvSize: csvContent.length,
    jsonSize: jsonContent.length,
    compressionRatio,
  }
}

// ğŸ”¥ FIXED: Test single chunk vá»›i proper boolean cache
const testSingleChunkCSV = async (chunk: any[], keyIndex: number): Promise<boolean> => {
  const cacheKey = `test_${keyIndex}`

  // Check cache first - return boolean
  if (testResultsCache.has(cacheKey)) {
    console.log(`ğŸ”„ Using cached test result for API ${keyIndex + 1}`)
    return testResultsCache.get(cacheKey)!
  }

  try {
    const apiKey = API_KEYS[keyIndex]
    console.log(`ğŸ§ª Test CSV chunk: ${chunk.length} records for API ${keyIndex + 1}`)

    const groq = createGroqClient(apiKey)

    // ğŸ”¥ FIXED: Thá»­ compound-beta trÆ°á»›c
    const testCompletion = await groq.chat.completions.create({
      model: "compound-beta", // Sá»­ dá»¥ng chÃ­nh xÃ¡c model user muá»‘n
      messages: [
        {
          role: "user",
          content: "Test: Return 'OK'",
        },
      ],
      temperature: 0.1,
      max_tokens: 5,
    })

    const response = testCompletion?.choices?.[0]?.message?.content
    const success = !!response

    // Cache boolean result
    testResultsCache.set(cacheKey, success)

    console.log(`âœ… Key ${keyIndex + 1} compound-beta test: ${success ? "OK" : "FAILED"}`)
    console.log(`ğŸ” Response: "${response}"`)

    return success
  } catch (error) {
    console.log(`âŒ Key ${keyIndex + 1} compound-beta test failed: ${error}`)

    // ğŸ”¥ FALLBACK: Thá»­ compound-beta-mini
    try {
      console.log(`ğŸ”„ Trying compound-beta-mini fallback for API ${keyIndex + 1}`)
      const groq = createGroqClient(API_KEYS[keyIndex])

      const fallbackCompletion = await groq.chat.completions.create({
        model: "compound-beta-mini",
        messages: [
          {
            role: "user",
            content: "Test: Return 'OK'",
          },
        ],
        temperature: 0.1,
        max_tokens: 5,
      })

      const fallbackResponse = fallbackCompletion?.choices?.[0]?.message?.content
      const fallbackSuccess = !!fallbackResponse

      testResultsCache.set(cacheKey, fallbackSuccess)
      console.log(`âœ… Key ${keyIndex + 1} compound-beta-mini fallback: ${fallbackSuccess ? "OK" : "FAILED"}`)

      return fallbackSuccess
    } catch (fallbackError) {
      console.log(`âŒ Key ${keyIndex + 1} compound-beta-mini also failed: ${fallbackError}`)
      testResultsCache.set(cacheKey, false)
      return false
    }
  }
}

const createGroqClient = (apiKey: string): Groq => {
  return new Groq({
    apiKey: apiKey,
    dangerouslyAllowBrowser: true,
  })
}

// ğŸ”¥ UPDATED: Helper function Ä‘á»ƒ phÃ¢n tÃ­ch vá»›i compound-beta models
const analyzeWithSingleKey = async (apiKey: string, keyIndex: number, prompt: string): Promise<string> => {
  // ğŸ”¥ FIXED: Thá»­ compound models trÆ°á»›c
  const modelsToTry = ["compound-beta", "compound-beta-mini", "llama-3.1-8b-instant"]

  for (const modelName of modelsToTry) {
    try {
      const promptTokens = estimateTokens(prompt)
      console.log(`ğŸ¤– ANALYSIS vá»›i API 5 (Key ${keyIndex + 1}) - Model: ${modelName}:`)
      console.log(`  ğŸ¯ Analysis INPUT tokens: ${promptTokens}`)

      const groq = createGroqClient(apiKey)
      const startTime = Date.now()

      // ğŸ” DEBUG: Log model request
      console.log(`ğŸ” DEBUG: Requesting model "${modelName}"`)

      const completion = await groq.chat.completions.create({
        model: modelName,
        messages: [
          {
            role: "user",
            content: prompt,
          },
        ],
        temperature: 0.7,
        max_tokens: 4000,
      })

      const responseTime = Date.now() - startTime

      // ğŸ” DEBUG: Log actual response
      console.log(`ğŸ” DEBUG: Response received from model request "${modelName}"`)
      console.log(`ğŸ” DEBUG: Completion model field:`, completion.model)

      if (!completion?.choices?.[0]?.message?.content) {
        console.log(`âš ï¸ No response content from ${modelName}`)
        continue // Try next model
      }

      const analysis = completion.choices[0].message.content || "KhÃ´ng cÃ³ phÃ¢n tÃ­ch"
      const outputTokens = estimateTokens(analysis)

      console.log(`âœ… CSV ANALYSIS SUCCESS with ${modelName}:`)
      console.log(`  ğŸ¯ OUTPUT tokens: ${outputTokens}`)
      console.log(`  âš¡ Processing time: ${responseTime}ms`)
      console.log(`  ğŸ” Actual model used: ${completion.model || "unknown"}`)

      return analysis
    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error)
      console.error(`âŒ Model ${modelName} failed: ${errorMsg}`)

      if (modelName === modelsToTry[modelsToTry.length - 1]) {
        // Last model failed
        return `âŒ Táº¥t cáº£ models Ä‘á»u tháº¥t báº¡i. Lá»—i cuá»‘i: ${errorMsg}`
      }
      // Continue to next model
    }
  }

  return "âŒ KhÃ´ng thá»ƒ phÃ¢n tÃ­ch vá»›i báº¥t ká»³ model nÃ o"
}

// ğŸ”¥ UPDATED: Optimize data chunk vá»›i compound-beta models
const optimizeDataChunk = async (
  apiKey: string,
  keyIndex: number,
  dataChunk: any[],
  chunkIndex: number,
  totalChunks: number,
  targetTokens: number,
): Promise<{ success: boolean; optimizedData: string; keyIndex: number; error?: string }> => {
  try {
    // Convert to CSV first
    const csvContent = convertToCSV(dataChunk)
    const estimatedTokens = estimateTokens(csvContent)

    console.log(`\nğŸ”§ ===== API ${keyIndex + 1} - CSV CHUNK ${chunkIndex + 1}/${totalChunks} =====`)
    console.log(`ğŸ“Š CSV TOKEN ANALYSIS:`)
    console.log(`  ğŸ¯ Target tokens for this API: ${targetTokens}`)
    console.log(`  ğŸ“ Actual records: ${dataChunk.length}`)
    console.log(`  ğŸ“„ CSV characters: ${csvContent.length}`)
    console.log(`  ğŸ¯ INPUT TOKENS: ${estimatedTokens}`)

    // Validate CSV
    const csvValidation = validateCSV(csvContent)
    if (!csvValidation.isValid) {
      console.log(`âŒ CSV VALIDATION FAILED: ${csvValidation.error}`)
      return {
        success: false,
        optimizedData: "",
        keyIndex: keyIndex,
        error: `CSV validation failed: ${csvValidation.error}`,
      }
    }

    console.log(`âœ… CSV Validation: ${csvValidation.rowCount} valid rows`)

    const groq = createGroqClient(apiKey)

    // ğŸ”¥ UPDATED: Prompt cho CSV optimization
    const optimizePrompt = `Clean this CSV data, remove empty rows, keep format:

${csvContent}

Return clean CSV only:`

    const promptTokens = estimateTokens(optimizePrompt)
    console.log(`ğŸ“¤ SENDING CSV REQUEST:`)
    console.log(`  ğŸ¯ Total INPUT tokens: ${promptTokens}`)
    console.log(`  âš¡ Target Model: compound-beta`)

    const startTime = Date.now()

    // ğŸ”¥ FIXED: Thá»­ compound-beta trÆ°á»›c
    let completion
    let actualModel = "unknown"

    try {
      console.log(`ğŸ” DEBUG: Requesting compound-beta for optimization`)
      completion = await groq.chat.completions.create({
        model: "compound-beta",
        messages: [{ role: "user", content: optimizePrompt }],
        temperature: 0.1,
        max_tokens: 2000,
      })
      actualModel = "compound-beta"
    } catch (error) {
      console.log(`âš ï¸ compound-beta failed, trying compound-beta-mini: ${error}`)
      completion = await groq.chat.completions.create({
        model: "compound-beta-mini",
        messages: [{ role: "user", content: optimizePrompt }],
        temperature: 0.1,
        max_tokens: 2000,
      })
      actualModel = "compound-beta-mini"
    }

    const responseTime = Date.now() - startTime
    console.log(`ğŸ“¥ CSV RESPONSE RECEIVED (${responseTime}ms) from ${actualModel}:`)
    console.log(`ğŸ” DEBUG: Completion model field:`, completion.model)

    if (!completion?.choices?.[0]?.message?.content) {
      throw new Error("Empty response from API")
    }

    const optimizedCSV = completion.choices[0].message.content.trim()
    const outputTokens = estimateTokens(optimizedCSV)
    const compressionRatio = Math.round((outputTokens / estimatedTokens) * 100)

    console.log(`ğŸ“Š CSV OUTPUT ANALYSIS:`)
    console.log(`  ğŸ“„ Response chars: ${optimizedCSV.length}`)
    console.log(`  ğŸ¯ OUTPUT TOKENS: ${outputTokens}`)
    console.log(`  ğŸ“‰ Compression: ${compressionRatio}%`)
    console.log(`  âš¡ Processing time: ${responseTime}ms`)
    console.log(`  ğŸ” Actual model used: ${completion.model || actualModel}`)

    // Validate optimized CSV
    const optimizedValidation = validateCSV(optimizedCSV)
    if (optimizedValidation.isValid) {
      console.log(`âœ… CSV OPTIMIZATION SUCCESS:`)
      console.log(`  ğŸ“Š Valid CSV with ${optimizedValidation.rowCount} rows`)
      console.log(`===== END CSV API ${keyIndex + 1} =====\n`)

      return {
        success: true,
        optimizedData: optimizedCSV,
        keyIndex: keyIndex,
      }
    } else {
      console.log(`âŒ CSV OPTIMIZATION VALIDATION FAILED:`)
      console.log(`  ğŸ” Response preview: ${optimizedCSV.substring(0, 200)}...`)
      throw new Error(`Invalid optimized CSV: ${optimizedValidation.error}`)
    }
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error)
    console.error(`âŒ CSV API ${keyIndex + 1} FAILED: ${errorMsg}`)

    return {
      success: false,
      optimizedData: "",
      keyIndex: keyIndex,
      error: errorMsg,
    }
  }
}

// ğŸ”¥ UPDATED: Function chÃ­nh vá»›i CSV format - GIáº¢M THIá»‚U API CALLS
export const preprocessDataWithPipeline = async (
  data: any[],
  tableName: string,
): Promise<{ success: boolean; optimizedData: string; analysis: string; keyUsage: any }> => {
  try {
    console.log(`ğŸš€ Báº¯t Ä‘áº§u CSV Data Preprocessing Pipeline vá»›i ${data.length} records`)

    if (!API_KEYS || API_KEYS.length < 5) {
      throw new Error("Cáº§n Ã­t nháº¥t 5 API keys (4 cho optimize + 1 cho analysis)")
    }

    // ğŸ”¥ DEBUG: Test available models first
    console.log(`ğŸ” DEBUG: Testing available models...`)
    const workingModels = await testAvailableModels()
    console.log(`âœ… Working models: ${workingModels.join(", ")}`)

    // ğŸ”¥ BÆ¯á»šC 1: TÃ­nh toÃ¡n CSV token distribution
    console.log(`ğŸ“Š BÆ¯á»šC 1: TÃ­nh toÃ¡n CSV token distribution...`)
    const tokenDistribution = calculateTokenDistribution(data)

    if (tokenDistribution.distribution.length === 0) {
      throw new Error("KhÃ´ng thá»ƒ chia dá»¯ liá»‡u thÃ nh chunks")
    }

    console.log(`ğŸ“Š CSV vs JSON Comparison:`)
    console.log(`  ğŸ“„ JSON: ${tokenDistribution.jsonSize} chars`)
    console.log(`  ğŸ“„ CSV: ${tokenDistribution.csvSize} chars`)
    console.log(
      `  ğŸ“‰ Compression: ${tokenDistribution.compressionRatio}% (${100 - tokenDistribution.compressionRatio}% reduction)`,
    )

    // ğŸ”¥ BÆ¯á»šC 2: Test API keys - CHá»ˆ 1 Láº¦N
    console.log(`ğŸ§ª Test API keys cho CSV optimize...`)
    const keyTests = await Promise.all(API_KEYS.slice(0, 4).map((key, index) => testSingleChunkCSV([data[0]], index)))
    const workingKeys = keyTests.filter(Boolean).length
    console.log(`ğŸ”‘ ${workingKeys}/4 CSV optimize APIs hoáº¡t Ä‘á»™ng`)

    if (workingKeys === 0) {
      // Fallback vá»›i raw CSV
      const rawCSV = convertToCSV(data)
      return {
        success: true,
        optimizedData: rawCSV,
        analysis: `âš ï¸ KhÃ´ng cÃ³ API keys hoáº¡t Ä‘á»™ng, sá»­ dá»¥ng raw CSV vá»›i ${data.length} records.`,
        keyUsage: { error: true, format: "CSV", fallback: true },
      }
    }

    // ğŸ”¥ BÆ¯á»šC 3: Optimize tá»«ng chunk - CHá»ˆ 1 REQUEST PER API
    console.log(`â³ BÆ¯á»šC 3: CSV Optimize ${tokenDistribution.distribution.length} chunks vá»›i ${workingKeys} APIs...`)

    const optimizeResults = []

    // Xá»­ lÃ½ tá»«ng chunk vá»›i API tÆ°Æ¡ng á»©ng - KHÃ”NG RETRY
    for (let i = 0; i < Math.min(4, tokenDistribution.distribution.length); i++) {
      const chunk = tokenDistribution.distribution[i]
      const keyIndex = i // API 1,2,3,4

      console.log(`ğŸ”§ Xá»­ lÃ½ CSV chunk ${i + 1} vá»›i API ${keyIndex + 1}`)

      // CHá»ˆ 1 REQUEST - KHÃ”NG RETRY
      const result = await optimizeDataChunk(
        API_KEYS[keyIndex],
        keyIndex,
        chunk,
        i,
        tokenDistribution.distribution.length,
        tokenDistribution.tokensPerAPI,
      )

      optimizeResults.push(result)

      // Delay nhá» giá»¯a cÃ¡c API calls
      if (i < tokenDistribution.distribution.length - 1) {
        await new Promise((resolve) => setTimeout(resolve, 500))
      }
    }

    // Kiá»ƒm tra káº¿t quáº£ optimize
    const successfulOptimizes = optimizeResults.filter((r) => r && r.success)
    console.log(`ğŸ“Š CSV Optimize results: ${successfulOptimizes.length}/4 APIs thÃ nh cÃ´ng`)

    // Náº¿u táº¥t cáº£ tháº¥t báº¡i, sá»­ dá»¥ng raw CSV
    if (successfulOptimizes.length === 0) {
      const rawCSV = convertToCSV(data)
      return {
        success: true,
        optimizedData: rawCSV,
        analysis: `âš ï¸ Optimize tháº¥t báº¡i, sá»­ dá»¥ng raw CSV vá»›i ${data.length} records.`,
        keyUsage: {
          totalKeys: API_KEYS.length,
          optimizeKeys: 0,
          fallback: true,
          format: "CSV",
        },
      }
    }

    // ğŸ”¥ BÆ¯á»šC 4: Gá»™p CSV data Ä‘Ã£ optimize
    console.log(`ğŸ“Š BÆ¯á»šC 4: Gá»™p ${successfulOptimizes.length} CSV chunks optimize`)

    let combinedCSVData = ""
    let headers = ""
    const allRows: string[] = []
    let validChunks = 0

    successfulOptimizes.forEach((result, index) => {
      try {
        const csvLines = result.optimizedData.trim().split("\n")
        if (csvLines.length < 2) return

        if (validChunks === 0) {
          headers = csvLines[0]
          allRows.push(...csvLines.slice(1))
        } else {
          allRows.push(...csvLines.slice(1))
        }
        validChunks++
      } catch (parseError) {
        console.warn(`âš ï¸ KhÃ´ng thá»ƒ parse CSV result tá»« API ${result.keyIndex + 1}:`, parseError)
      }
    })

    combinedCSVData = headers + "\n" + allRows.join("\n")
    const finalTokens = estimateTokens(combinedCSVData)

    // ğŸ”¥ BÆ¯á»šC 5: PhÃ¢n tÃ­ch tá»•ng há»£p - CHá»ˆ 1 REQUEST
    console.log(`ğŸ¤– BÆ¯á»šC 5: PhÃ¢n tÃ­ch tá»•ng há»£p CSV vá»›i API 5`)

    const analysisPrompt = `Báº¡n lÃ  má»™t AI analyst chuyÃªn nghiá»‡p. DÆ°á»›i Ä‘Ã¢y lÃ  dá»¯ liá»‡u tá»« báº£ng "${tableName}" trong CSV format (${data.length} records gá»‘c, ${validChunks}/4 APIs thÃ nh cÃ´ng):

${combinedCSVData}

HÃ£y phÃ¢n tÃ­ch chi tiáº¿t dá»¯ liá»‡u CSV nÃ y:
1. ğŸ“Š Tá»•ng quan vá» dá»¯ liá»‡u vÃ  cáº¥u trÃºc CSV
2. ğŸ“ˆ Thá»‘ng kÃª quan trá»ng tá»« cÃ¡c cá»™t  
3. ğŸ” Patterns vÃ  insights tá»« dá»¯ liá»‡u
4. ğŸ’¡ Nháº­n xÃ©t vÃ  Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng dá»¯ liá»‡u

Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, chi tiáº¿t vÃ  cÃ³ cáº¥u trÃºc.`

    const finalAnalysis = await analyzeWithSingleKey(API_KEYS[4], 4, analysisPrompt)

    const keyUsage = {
      totalKeys: API_KEYS.length,
      optimizeKeys: successfulOptimizes.length,
      analysisKey: 1,
      successRate: `${Math.round((successfulOptimizes.length / 4) * 100)}%`,
      chunks: tokenDistribution.distribution.length,
      successfulChunks: validChunks,
      finalDataSize: combinedCSVData.length,
      finalTokens: finalTokens,
      format: "CSV",
      csvCompressionVsJson: `${tokenDistribution.compressionRatio}%`,
      workingModels: workingModels,
    }

    return {
      success: true,
      optimizedData: combinedCSVData,
      analysis: finalAnalysis,
      keyUsage: keyUsage,
    }
  } catch (error) {
    console.error("âŒ CSV Data Preprocessing Pipeline failed:", error)
    return {
      success: false,
      optimizedData: "",
      analysis: `âŒ Lá»—i CSV preprocessing pipeline: ${error}`,
      keyUsage: { error: true, format: "CSV" },
    }
  }
}

// ğŸ”¥ UPDATED: Function tráº£ lá»i cÃ¢u há»i vá»›i CSV data - CHá»ˆ 1 REQUEST
export const answerQuestionWithOptimizedData = async (
  optimizedCSVData: string,
  tableName: string,
  question: string,
  originalRecordCount: number,
): Promise<string> => {
  try {
    console.log(`ğŸ¤” Tráº£ lá»i cÃ¢u há»i vá»›i optimized CSV data (${originalRecordCount} records)`)

    const questionPrompt = `Báº¡n lÃ  má»™t AI assistant thÃ´ng minh. DÆ°á»›i Ä‘Ã¢y lÃ  TOÃ€N Bá»˜ dá»¯ liá»‡u tá»« báº£ng "${tableName}" trong CSV format (${originalRecordCount} records):

${optimizedCSVData}

CÃ¢u há»i: ${question}

HÆ°á»›ng dáº«n phÃ¢n tÃ­ch CSV:
- DÃ²ng Ä‘áº§u tiÃªn lÃ  headers (tÃªn cá»™t)
- CÃ¡c dÃ²ng tiáº¿p theo lÃ  dá»¯ liá»‡u
- HÃ£y phÃ¢n tÃ­ch theo cá»™t vÃ  tÃ¬m patterns
- ÄÆ°a ra sá»‘ liá»‡u cá»¥ thá»ƒ vÃ  insights

Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t:`

    // CHá»ˆ 1 REQUEST DUY NHáº¤T
    return await analyzeWithSingleKey(API_KEYS[4], 4, questionPrompt)
  } catch (error) {
    console.error("âŒ answerQuestionWithOptimizedData failed:", error)
    return `âŒ Lá»—i khi tráº£ lá»i cÃ¢u há»i vá»›i CSV: ${error}`
  }
}

// Export function chÃ­nh
export const analyzeDataWithParallelKeys = preprocessDataWithPipeline

// ğŸ”¥ UPDATED: Function tráº£ lá»i cÃ¢u há»i - sá»­ dá»¥ng CSV optimized data
export const answerQuestionWithData = async (
  data: any[],
  tableName: string,
  question: string,
  previousAnalysis?: string,
  optimizedData?: string,
): Promise<string> => {
  try {
    if (optimizedData && optimizedData.length > 0) {
      return await answerQuestionWithOptimizedData(optimizedData, tableName, question, data.length)
    } else {
      const quickCSV = convertToCSV(data.slice(0, 30))
      return await answerQuestionWithOptimizedData(quickCSV, tableName, question, data.length)
    }
  } catch (error) {
    console.error("âŒ answerQuestionWithData failed:", error)
    return `âŒ Lá»—i khi tráº£ lá»i cÃ¢u há»i: ${error}`
  }
}

// ğŸ”¥ FIXED: Test functions vá»›i proper type handling
export const testAllApiKeys = async (): Promise<{
  success: boolean
  message: string
  workingKeys: number
  totalKeys: number
  keyDetails: any[]
}> => {
  console.log(`ğŸ§ª Testing ${API_KEYS.length} API keys vá»›i compound-beta models...`)

  // CHá»ˆ TEST 1 Láº¦N vá»›i proper type handling
  const testPromises = API_KEYS.map(async (apiKey, index) => {
    const cacheKey = `full_test_${index}`

    // Check detailed cache first
    if (detailedTestCache.has(cacheKey)) {
      console.log(`ğŸ”„ Using cached detailed test result for API ${index + 1}`)
      return detailedTestCache.get(cacheKey)
    }

    try {
      const groq = createGroqClient(apiKey)

      // ğŸ”¥ FIXED: Test vá»›i compound-beta
      console.log(`ğŸ§ª Testing API ${index + 1} with compound-beta`)
      const testCompletion = await groq.chat.completions.create({
        model: "compound-beta",
        messages: [
          {
            role: "user",
            content: "Test: Return 'OK'",
          },
        ],
        temperature: 0.1,
        max_tokens: 5,
      })

      const response = testCompletion?.choices?.[0]?.message?.content || "No response"
      console.log(`âœ… CSV API ${index + 1}: OK with compound-beta`)
      console.log(`ğŸ” DEBUG: Actual model used: ${testCompletion.model}`)

      const result = {
        keyIndex: index + 1,
        status: "success" as const,
        response: response,
        preview: `${apiKey.substring(0, 10)}...${apiKey.substring(apiKey.length - 4)}`,
        role: index < 4 ? "CSV optimize" : "CSV analysis",
        actualModel: testCompletion.model || "compound-beta",
      }

      // Cache detailed result
      detailedTestCache.set(cacheKey, result)
      // Also cache boolean result for other functions
      testResultsCache.set(`test_${index}`, true)

      return result
    } catch (error) {
      console.log(`âŒ CSV API ${index + 1} compound-beta failed: ${error}`)

      // ğŸ”¥ FALLBACK: Try compound-beta-mini
      try {
        console.log(`ğŸ”„ Trying compound-beta-mini for API ${index + 1}`)
        const groq = createGroqClient(apiKey)

        const fallbackCompletion = await groq.chat.completions.create({
          model: "compound-beta-mini",
          messages: [
            {
              role: "user",
              content: "Test: Return 'OK'",
            },
          ],
          temperature: 0.1,
          max_tokens: 5,
        })

        const response = fallbackCompletion?.choices?.[0]?.message?.content || "No response"
        console.log(`âœ… CSV API ${index + 1}: OK with compound-beta-mini`)
        console.log(`ğŸ” DEBUG: Actual model used: ${fallbackCompletion.model}`)

        const result = {
          keyIndex: index + 1,
          status: "success" as const,
          response: response,
          preview: `${apiKey.substring(0, 10)}...${apiKey.substring(apiKey.length - 4)}`,
          role: index < 4 ? "CSV optimize" : "CSV analysis",
          actualModel: fallbackCompletion.model || "compound-beta-mini",
        }

        // Cache detailed result
        detailedTestCache.set(cacheKey, result)
        // Also cache boolean result for other functions
        testResultsCache.set(`test_${index}`, true)

        return result
      } catch (fallbackError) {
        console.log(`âŒ CSV API ${index + 1} compound-beta-mini also failed: ${fallbackError}`)
        const result = {
          keyIndex: index + 1,
          status: "failed" as const,
          error: error instanceof Error ? error.message : String(error),
          preview: `${apiKey.substring(0, 10)}...${apiKey.substring(apiKey.length - 4)}`,
          role: index < 4 ? "CSV optimize" : "CSV analysis",
        }

        // Cache detailed result
        detailedTestCache.set(cacheKey, result)
        // Also cache boolean result for other functions
        testResultsCache.set(`test_${index}`, false)

        return result
      }
    }
  })

  const results = await Promise.all(testPromises)
  const workingKeys = results.filter((r) => r.status === "success").length

  return {
    success: workingKeys > 0,
    message: `${workingKeys}/${API_KEYS.length} API keys hoáº¡t Ä‘á»™ng vá»›i compound-beta models (4 optimize + 1 analysis)`,
    workingKeys: workingKeys,
    totalKeys: API_KEYS.length,
    keyDetails: results,
  }
}

// Backward compatibility functions
export const askAI = async (context: string, question: string): Promise<string> => {
  return await answerQuestionWithData([], "Unknown", question)
}

export const askAIWithFullData = async (data: any[], tableName: string, question: string): Promise<string> => {
  return await answerQuestionWithData(data, tableName, question)
}

export const askAIWithRawData = async (data: any[], tableName: string, question: string): Promise<string> => {
  return await answerQuestionWithData(data, tableName, question)
}

export const testGroqAPI = async () => {
  const result = await testAllApiKeys()
  return {
    success: result.success,
    message: result.message,
    workingModel: "compound-beta",
    format: "CSV",
  }
}

export const getAvailableModels = (): string[] => {
  return AVAILABLE_MODELS
}

export const getApiKeysInfo = () => {
  return {
    totalKeys: API_KEYS.length,
    keysPreview: API_KEYS.map(
      (key, index) =>
        `API ${index + 1}: ${key.substring(0, 10)}...${key.substring(key.length - 4)} (${index < 4 ? "CSV optimize" : "CSV analysis"})`,
    ),
    format: "CSV",
  }
}

// ğŸ”¥ FIXED: Clear cache function
export const clearApiCache = () => {
  apiCallCache.clear()
  testResultsCache.clear()
  detailedTestCache.clear()
  console.log("ğŸ”„ API cache cleared")
}

// ğŸ”¥ NEW: Export debug functions
export { testAvailableModels, debugModelCall }
