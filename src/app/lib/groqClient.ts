import { Groq } from "groq-sdk"

// Danh s√°ch API keys
const API_KEYS = [
  process.env.NEXT_PUBLIC_GROQ_API_KEY_1 || "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",
  process.env.NEXT_PUBLIC_GROQ_API_KEY_2 || "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",
  process.env.NEXT_PUBLIC_GROQ_API_KEY_3 || "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",
  process.env.NEXT_PUBLIC_GROQ_API_KEY_4 || "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",
  process.env.NEXT_PUBLIC_GROQ_API_KEY_5 || "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",
].filter((key) => key && !key.includes("account") && key.startsWith("gsk_"))

const AVAILABLE_MODELS = ["meta-llama/llama-guard-4-12b"]

// ∆Ø·ªõc t√≠nh s·ªë tokens (1 token ‚âà 4 k√Ω t·ª±)
const estimateTokens = (text: string): number => {
  return Math.ceil(text.length / 4)
}

// Chia d·ªØ li·ªáu CSV th√†nh chunks
const calculateTokenDistribution = (
  data: string,
): {
  totalTokens: number
  tokensPerAPI: number
  chunksPerAPI: number[]
  distribution: string[]
} => {
  const totalTokens = estimateTokens(data)
  const tokensPerAPI = Math.ceil(totalTokens / 4)

  console.log(`üìä ===== TOKEN DISTRIBUTION CALCULATION =====`)
  console.log(`üéØ Total characters: ${data.length}`)
  console.log(`üéØ Total records: ${data.split("\n").length - 1}`)
  console.log(`üéØ TOTAL TOKENS: ${totalTokens}`)
  console.log(`üìä Tokens per API (4 APIs): ${tokensPerAPI}`)
  console.log(`‚ö° Model: ${AVAILABLE_MODELS[0]}`)

  const lines = data.split("\n").filter((line) => line.trim())
  const chunks: string[] = []
  const chunksPerAPI: number[] = []
  let currentChunk: string[] = [lines[0]] // Gi·ªØ header
  let currentTokens = estimateTokens(lines[0])
  let currentAPIIndex = 0

  for (let i = 1; i < lines.length; i++) {
    const lineTokens = estimateTokens(lines[i])
    if (currentTokens + lineTokens > tokensPerAPI && currentChunk.length > 1 && currentAPIIndex < 3) {
      console.log(`üìä API ${currentAPIIndex + 1} chunk: ${currentChunk.length - 1} records, ${currentTokens} tokens`)
      chunks.push(currentChunk.join("\n"))
      chunksPerAPI.push(currentChunk.length - 1)
      currentChunk = [lines[0]]
      currentTokens = estimateTokens(lines[0])
      currentAPIIndex++
    }
    currentChunk.push(lines[i])
    currentTokens += lineTokens
  }

  if (currentChunk.length > 1) {
    console.log(`üìä API ${currentAPIIndex + 1} chunk: ${currentChunk.length - 1} records, ${currentTokens} tokens`)
    chunks.push(currentChunk.join("\n"))
    chunksPerAPI.push(currentChunk.length - 1)
  }

  while (chunks.length < 4 && lines.length > 5) {
    const remainingRecords = lines.length - 1 - chunks.reduce((sum, chunk) => sum + chunk.split("\n").length - 1, 0)
    if (remainingRecords > 0) {
      const recordsPerChunk = Math.ceil(remainingRecords / (4 - chunks.length))
      const startIndex = chunks.reduce((sum, chunk) => sum + chunk.split("\n").length - 1, 0) + 1
      const newChunk = [lines[0], ...lines.slice(startIndex, startIndex + recordsPerChunk)]
      if (newChunk.length > 1) {
        const chunkTokens = estimateTokens(newChunk.join("\n"))
        console.log(`üìä API ${chunks.length + 1} chunk (balanced): ${newChunk.length - 1} records, ${chunkTokens} tokens`)
        chunks.push(newChunk.join("\n"))
        chunksPerAPI.push(newChunk.length - 1)
      }
    } else {
      break
    }
  }

  console.log(`üìä FINAL DISTRIBUTION:`)
  chunks.forEach((chunk, index) => {
    const chunkTokens = estimateTokens(chunk)
    console.log(`  API ${index + 1}: ${chunk.split("\n").length - 1} records, ${chunkTokens} tokens`)
  })
  console.log(`  API 5: T·ªïng h·ª£p v√† tr·∫£ l·ªùi c√¢u h·ªèi`)
  console.log(`===============================================`)

  return {
    totalTokens,
    tokensPerAPI,
    chunksPerAPI,
    distribution: chunks,
  }
}

// Test single chunk
const testSingleChunk = async (chunk: string, keyIndex: number): Promise<boolean> => {
  try {
    const apiKey = API_KEYS[keyIndex]
    const estimatedTokens = estimateTokens(chunk)

    console.log(`üß™ Test chunk: ${chunk.split("\n").length - 1} records, ~${estimatedTokens} tokens`)

    if (estimatedTokens > 15000) {
      console.log(`‚ö†Ô∏è Chunk qu√° l·ªõn (${estimatedTokens} tokens)`)
      return false
    }

    const groq = createGroqClient(apiKey)
    const testCompletion = await groq.chat.completions.create({
      model: AVAILABLE_MODELS[0],
      messages: [{ role: "user", content: "Test: Return 'OK'" }],
      temperature: 0.1,
      max_tokens: 10,
    })

    const response = testCompletion?.choices?.[0]?.message?.content
    console.log(`‚úÖ Key ${keyIndex + 1} test OK: ${response}`)
    return true
  } catch (error) {
    console.log(`‚ùå Key ${keyIndex + 1} test failed: ${error}`)
    return false
  }
}

// T·∫°o Groq client
const createGroqClient = (apiKey: string): Groq => {
  return new Groq({
    apiKey: apiKey,
    dangerouslyAllowBrowser: true,
  })
}

// Ph√¢n t√≠ch v·ªõi single key
const analyzeWithSingleKey = async (apiKey: string, keyIndex: number, prompt: string): Promise<string> => {
  try {
    const promptTokens = estimateTokens(prompt)
    console.log(`ü§ñ FINAL ANALYSIS v·ªõi API 5 (Key ${keyIndex + 1}):`)
    console.log(`  üéØ Analysis INPUT tokens: ${promptTokens}`)
    console.log(`  ‚ö° Model: ${AVAILABLE_MODELS[0]}`)

    const groq = createGroqClient(apiKey)
    const startTime = Date.now()
    const completion = await Promise.race([
      groq.chat.completions.create({
        model: AVAILABLE_MODELS[0],
        messages: [{ role: "user", content: prompt }],
        temperature: 0.7,
        max_tokens: 25000,
      }),
      new Promise((_, reject) => setTimeout(() => reject(new Error("Timeout 90s")), 90000)),
    ]) as any

    const responseTime = Date.now() - startTime
    const analysis = completion.choices[0].message.content || "Kh√¥ng c√≥ ph√¢n t√≠ch"
    const outputTokens = estimateTokens(analysis)

    console.log(`‚úÖ ANALYSIS COMPLETE:`)
    console.log(`  üéØ OUTPUT tokens: ${outputTokens}`)
    console.log(`  ‚ö° Processing time: ${responseTime}ms`)

    return analysis
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error)
    console.error(`‚ùå Analysis failed: ${errorMsg}`)
    return `‚ùå Kh√¥ng th·ªÉ ph√¢n t√≠ch: ${errorMsg}`
  }
}

// T·ªëi ∆∞u h√≥a chunk CSV
const optimizeDataChunk = async (
  apiKey: string,
  keyIndex: number,
  dataChunk: string,
  chunkIndex: number,
  totalChunks: number,
  targetTokens: number,
): Promise<{ success: boolean; optimizedData: string; keyIndex: number; error?: string }> => {
  try {
    const estimatedTokens = estimateTokens(dataChunk)
    console.log(`\nüîß ===== API ${keyIndex + 1} - CHUNK ${chunkIndex + 1}/${totalChunks} =====`)
    console.log(`üìä TOKEN ANALYSIS:`)
    console.log(`  üéØ Target tokens: ${targetTokens}`)
    console.log(`  üìù Records: ${dataChunk.split("\n").length - 1}`)
    console.log(`  üìÑ Characters: ${dataChunk.length}`)
    console.log(`  üéØ INPUT TOKENS: ${estimatedTokens}`)

    if (estimatedTokens > 15000) {
      console.log(`‚ùå CHUNK QU√Å L·ªöN: ${estimatedTokens} tokens > 15000 limit`)
      return {
        success: false,
        optimizedData: "",
        keyIndex: keyIndex,
        error: `Chunk qu√° l·ªõn: ${estimatedTokens} tokens > 15000 limit`,
      }
    }

    const groq = createGroqClient(apiKey)
    const optimizePrompt = `Optimize CSV - remove columns with all null/empty values, compact values:
${dataChunk}
Return optimized CSV only:`

    const promptTokens = estimateTokens(optimizePrompt)
    console.log(`üì§ SENDING REQUEST:`)
    console.log(`  üéØ Total INPUT tokens: ${promptTokens}`)
    console.log(`  ‚ö° Model: ${AVAILABLE_MODELS[0]}`)

    const startTime = Date.now()
    const completion = await Promise.race([
      groq.chat.completions.create({
        model: AVAILABLE_MODELS[0],
        messages: [{ role: "user", content: optimizePrompt }],
        temperature: 0.1,
        max_tokens: 8000,
      }),
      new Promise((_, reject) => setTimeout(() => reject(new Error("Timeout 60s")), 60000)),
    ]) as any

    const responseTime = Date.now() - startTime
    const optimizedData = completion.choices[0].message.content.trim()
    const outputTokens = estimateTokens(optimizedData)

    console.log(`üìä OUTPUT ANALYSIS:`)
    console.log(`  üìÑ Response chars: ${optimizedData.length}`)
    console.log(`  üéØ OUTPUT TOKENS: ${outputTokens}`)
    console.log(`  üìâ Compression: ${Math.round((outputTokens / estimatedTokens) * 100)}%`)

    // Validate CSV
    const lines = optimizedData.split("\n")
    if (lines.length < 2) {
      throw new Error("Invalid CSV: Too few lines")
    }
    const headerLength = lines[0].split(",").length
    const invalidLines = lines.slice(1).filter((line) => line.split(",").length !== headerLength)
    if (invalidLines.length > 0) {
      throw new Error(`Invalid CSV: Mismatched column count in ${invalidLines.length} lines`)
    }

    console.log(`‚úÖ VALIDATION SUCCESS:`)
    console.log(`  üìä Valid CSV with ${lines.length - 1} records`)
    console.log(`===== END API ${keyIndex + 1} =====\n`)

    return {
      success: true,
      optimizedData: optimizedData,
      keyIndex: keyIndex,
    }
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error)
    console.error(`‚ùå API ${keyIndex + 1} FAILED: ${errorMsg}`)
    return {
      success: false,
      optimizedData: "",
      keyIndex: keyIndex,
      error: errorMsg,
    }
  }
}

// Debug chunk CSV
const debugOptimizeProcess = async (chunk: string, keyIndex: number): Promise<void> => {
  try {
    const estimatedTokens = estimateTokens(chunk)
    console.log(`üîç DEBUG API ${keyIndex + 1}:`)
    console.log(`  - Records: ${chunk.split("\n").length - 1}`)
    console.log(`  - Characters: ${chunk.length}`)
    console.log(`  - Estimated tokens: ${estimatedTokens}`)
    console.log(`  - Sample: ${chunk.split("\n")[0]}\n${chunk.split("\n")[1] || ""}...`)

    const apiKey = API_KEYS[keyIndex]
    const groq = createGroqClient(apiKey)
    const testResult = await groq.chat.completions.create({
      model: AVAILABLE_MODELS[0],
      messages: [{ role: "user", content: "Say 'test ok'" }],
      temperature: 0.1,
      max_tokens: 10,
    })

    console.log(`‚úÖ API ${keyIndex + 1} test result:`, testResult?.choices?.[0]?.message?.content)
  } catch (error) {
    console.error(`‚ùå DEBUG failed for API ${keyIndex + 1}:`, error)
  }
}

// Pipeline ch√≠nh
export const preprocessDataWithPipeline = async (
  data: string,
  tableName: string,
): Promise<{ success: boolean; optimizedData: string; analysis: string; keyUsage: any }> => {
  try {
    console.log(`üöÄ B·∫Øt ƒë·∫ßu Data Preprocessing Pipeline v·ªõi ${data.split("\n").length - 1} records`)

    if (!API_KEYS || API_KEYS.length < 5) {
      throw new Error("C·∫ßn √≠t nh·∫•t 5 API keys (4 cho optimize + 1 cho analysis)")
    }

    // B∆∞·ªõc 1: T√≠nh to√°n token distribution
    console.log(`üìä B∆Ø·ªöC 1: T√≠nh to√°n token distribution...`)
    const tokenDistribution = calculateTokenDistribution(data)

    if (tokenDistribution.distribution.length === 0) {
      throw new Error("Kh√¥ng th·ªÉ chia d·ªØ li·ªáu th√†nh chunks")
    }

    // Test API keys
    console.log(`üß™ Test 4 API keys ƒë·∫ßu...`)
    const keyTests = await Promise.all(
      API_KEYS.slice(0, 4).map((key, index) => testSingleChunk(data.split("\n").slice(0, 2).join("\n"), index)),
    )
    const workingKeys = keyTests.filter(Boolean).length
    console.log(`üîë ${workingKeys}/4 optimize APIs ho·∫°t ƒë·ªông`)

    if (workingKeys === 0) {
      throw new Error("Kh√¥ng c√≥ API keys n√†o ho·∫°t ƒë·ªông cho optimize")
    }

    const analysisKeyTest = await testSingleChunk(data.split("\n").slice(0, 2).join("\n"), 4)
    if (!analysisKeyTest) {
      console.log(`‚ö†Ô∏è API 5 kh√¥ng ho·∫°t ƒë·ªông, s·∫Ω d√πng API 1 cho analysis`)
    }

    // B∆∞·ªõc 2: Optimize chunks
    console.log(`‚è≥ B∆Ø·ªöC 2: Optimize ${tokenDistribution.distribution.length} chunks...`)
    const optimizeResults = []

    for (let i = 0; i < Math.min(4, tokenDistribution.distribution.length); i++) {
      const chunk = tokenDistribution.distribution[i]
      const keyIndex = i

      console.log(`üîß X·ª≠ l√Ω chunk ${i + 1} v·ªõi API ${keyIndex + 1}`)
      await debugOptimizeProcess(chunk, keyIndex)

      let result = null
      let retryCount = 0
      const maxRetries = 2

      while (retryCount <= maxRetries && (!result || !result.success)) {
        if (retryCount > 0) {
          console.log(`üîÑ Retry ${retryCount}/${maxRetries} cho API ${keyIndex + 1}`)
          await new Promise((resolve) => setTimeout(resolve, 3000))
        }

        result = await optimizeDataChunk(
          API_KEYS[keyIndex],
          keyIndex,
          chunk,
          i,
          tokenDistribution.distribution.length,
          tokenDistribution.tokensPerAPI,
        )

        if (result && result.success) {
          console.log(`‚úÖ API ${keyIndex + 1}: Th√†nh c√¥ng sau ${retryCount} retries`)
          break
        } else {
          console.log(`‚ùå API ${keyIndex + 1}: Th·∫•t b·∫°i l·∫ßn ${retryCount + 1} - ${result?.error || "Unknown error"}`)
        }

        retryCount++
      }

      optimizeResults.push(result || {
        success: false,
        optimizedData: "",
        keyIndex: keyIndex,
        error: "No result after retries",
      })

      if (i < tokenDistribution.distribution.length - 1) {
        await new Promise((resolve) => setTimeout(resolve, 1000))
      }
    }

    const successfulOptimizes = optimizeResults.filter((r) => r && r.success)
    console.log(`üìä Optimize results: ${successfulOptimizes.length}/4 APIs th√†nh c√¥ng`)

    if (successfulOptimizes.length === 0) {
      console.log(`üîÑ FALLBACK: T·∫•t c·∫£ optimize th·∫•t b·∫°i, s·ª≠ d·ª•ng raw CSV`)
      const rawData = data.split("\n").slice(0, 51).join("\n") // L·∫•y 50 records ƒë·∫ßu

      return {
        success: true,
        optimizedData: rawData,
        analysis: `‚ö†Ô∏è Kh√¥ng th·ªÉ optimize d·ªØ li·ªáu, s·ª≠ d·ª•ng 50 records ƒë·∫ßu ti√™n t·ª´ t·ªïng ${data.split("\n").length - 1} records`,
        keyUsage: {
          totalKeys: API_KEYS.length,
          optimizeKeys: 0,
          analysisKey: 1,
          failedKeys: 4,
          successRate: "0%",
          chunks: 1,
          successfulChunks: 0,
          finalDataSize: rawData.length,
          fallback: true,
          tokenDistribution,
        },
      }
    }

    // B∆∞·ªõc 3: G·ªôp d·ªØ li·ªáu
    let combinedOptimizedData = successfulOptimizes[0].optimizedData.split("\n")[0] + "\n" // L·∫•y header t·ª´ chunk ƒë·∫ßu
    let validChunks = 0

    for (const result of successfulOptimizes) {
      const lines = result.optimizedData.split("\n")
      if (lines.length > 1) {
        combinedOptimizedData += lines.slice(1).join("\n") + "\n"
        validChunks++
      }
    }

    const finalTokens = estimateTokens(combinedOptimizedData)
    console.log(`üìä B∆Ø·ªöC 3: ƒê√£ g·ªôp ${validChunks} chunks`)
    console.log(`  üìò Final data: ${combinedOptimizedData.length} chars`)
    console.log(`  üéØ Final tokens: ${finalTokens}`)
    console.log(`  üìâ Compression: ${Math.round((finalTokens / tokenDistribution.totalTokens) * 100)}%`)

    // B∆∞·ªõc 4: Ph√¢n t√≠ch t·ªïng h·ª£p
    const analysisKeyIndex = 4
    const analysisApiKey = API_KEYS[analysisKeyIndex]

    if (!analysisApiKey) {
      throw new Error("Kh√¥ng c√≥ API 5 cho ph√¢n t√≠ch")
    }

    console.log(`ü§ñ B∆Ø·ªöC 4: Ph√¢n t√≠ch t·ªïng h·ª£p v·ªõi API 5`)

    const analysisPrompt = `B·∫°n l√† m·ªôt AI analyst chuy√™n nghi·ªáp. D∆∞·ªõi ƒë√¢y l√† d·ªØ li·ªáu t·ª´ b·∫£ng "${tableName}" ·ªü ƒë·ªãnh d·∫°ng CSV ƒë√£ ƒë∆∞·ª£c optimize b·ªüi ${successfulOptimizes.length}/4 APIs (${data.split("\n").length - 1} records g·ªëc):

${combinedOptimizedData}

TokenDistribution Summary:
- Total original tokens: ${tokenDistribution.totalTokens}
- Tokens per API: ${tokenDistribution.tokensPerAPI}
- Final optimized tokens: ${finalTokens}
- Compression ratio: ${Math.round((finalTokens / tokenDistribution.totalTokens) * 100)}%

H√£y ph√¢n t√≠ch chi ti·∫øt:
1. üìä T·ªïng quan v·ªÅ d·ªØ li·ªáu
2. üìà Th·ªëng k√™ quan tr·ªçng
3. üîç Patterns v√† insights
4. üí° Nh·∫≠n x√©t v√† ƒë√°nh gi√°

Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, chi ti·∫øt v√† c√≥ c·∫•u tr√∫c.`

    const finalAnalysis = await analyzeWithSingleKey(analysisApiKey, analysisKeyIndex, analysisPrompt)

    const keyUsage = {
      totalKeys: API_KEYS.length,
      optimizeKeys: successfulOptimizes.length,
      analysisKey: 1,
      failedKeys: optimizeResults.length - successfulOptimizes.length,
      successRate: `${Math.round((successfulOptimizes.length / 4) * 100)}%`,
      chunks: tokenDistribution.distribution.length,
      successfulChunks: validChunks,
      finalDataSize: combinedOptimizedData.length,
      tokenDistribution,
      finalTokens,
      compressionRatio: `${Math.round((finalTokens / tokenDistribution.totalTokens) * 100)}%`,
    }

    return {
      success: true,
      optimizedData: combinedOptimizedData,
      analysis: finalAnalysis,
      keyUsage,
    }
  } catch (error) {
    console.error("‚ùå Data Preprocessing Pipeline failed:", error)
    return {
      success: false,
      optimizedData: "",
      analysis: `‚ùå L·ªói preprocessing pipeline: ${error}`,
      keyUsage: { error: true },
    }
  }
}

// Tr·∫£ l·ªùi c√¢u h·ªèi v·ªõi d·ªØ li·ªáu CSV
export const answerQuestionWithOptimizedData = async (
  optimizedData: string,
  tableName: string,
  question: string,
  originalRecordCount: number,
): Promise<string> => {
  try {
    console.log(`ü§î Tr·∫£ l·ªùi c√¢u h·ªèi v·ªõi optimized CSV (${originalRecordCount} records)`)

    const questionKeyIndex = 4
    const questionApiKey = API_KEYS[questionKeyIndex]

    if (!questionApiKey) {
      throw new Error("Kh√¥ng c√≥ API 5 ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi")
    }

    const questionPrompt = `B·∫°n l√† m·ªôt AI assistant th√¥ng minh. D∆∞·ªõi ƒë√¢y l√† TO√ÄN B·ªò d·ªØ li·ªáu t·ª´ b·∫£ng "${tableName}" (${originalRecordCount} records) ·ªü ƒë·ªãnh d·∫°ng CSV ƒë√£ ƒë∆∞·ª£c optimize:

${optimizedData}

ƒê√¢y l√† d·ªØ li·ªáu HO√ÄN CH·ªàNH t·ª´ ${originalRecordCount} b·∫£n ghi. H√£y tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch ch√≠nh x√°c v√† chi ti·∫øt.

C√¢u h·ªèi: ${question}

Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát:`

    return await analyzeWithSingleKey(questionApiKey, questionKeyIndex, questionPrompt)
  } catch (error) {
    console.error("‚ùå answerQuestionWithOptimizedData failed:", error)
    return `‚ùå L·ªói khi tr·∫£ l·ªùi c√¢u h·ªèi: ${error}`
  }
}

// Test t·∫•t c·∫£ API keys
export const testAllApiKeys = async (): Promise<{
  success: boolean
  message: string
  workingKeys: number
  totalKeys: number
  keyDetails: any[]
}> => {
  console.log(`üß™ Testing ${API_KEYS.length} API keys...`)

  const testPromises = API_KEYS.map(async (apiKey, index) => {
    try {
      const groq = createGroqClient(apiKey)
      const response = await groq.chat.completions.create({
        model: AVAILABLE_MODELS[0],
        messages: [{ role: "user", content: "Test: 1+1=?" }],
        temperature: 0.1,
        max_tokens: 50,
      })

      console.log(`‚úÖ API ${index + 1}: OK`)
      return {
        keyIndex: index + 1,
        status: "success" as const,
        response: response?.choices?.[0]?.message?.content || "No response",
        preview: `${apiKey.substring(0, 10)}...${apiKey.substring(apiKey.length - 4)}`,
        role: index < 4 ? "optimize" : "analysis",
      }
    } catch (error) {
      console.log(`‚ùå API ${index + 1}: ${error}`)
      return {
        keyIndex: index + 1,
        status: "failed" as const,
        error: error instanceof Error ? error.message : String(error),
        preview: `${apiKey.substring(0, 10)}...${apiKey.substring(apiKey.length - 4)}`,
        role: index < 4 ? "optimize" : "analysis",
      }
    }
  })

  const results = await Promise.all(testPromises)
  const workingKeys = results.filter((r) => r.status === "success").length

  return {
    success: workingKeys > 0,
    message: `${workingKeys}/${API_KEYS.length} API keys ho·∫°t ƒë·ªông`,
    workingKeys,
    totalKeys: API_KEYS.length,
    keyDetails: results,
  }
}

// C√°c h√†m kh√°c
export const getAvailableModels = (): string[] => {
  return AVAILABLE_MODELS
}

export const getApiKeysInfo = () => ({
  totalKeys: API_KEYS.length,
  keysPreview: API_KEYS.map(
    (key, index) =>
      `API ${index + 1}: ${key.substring(0, 10)}...${key.substring(key.length - 4)} (${index < 4 ? "optimize" : "analysis"})`,
  ),
})

// Backward compatibility
export const answerQuestionWithData = async (
  data: string,
  tableName: string,
  question: string,
  previousAnalysis?: string,
  optimizedData?: string,
): Promise<string> => {
  try {
    if (optimizedData && optimizedData.length > 0) {
      return await answerQuestionWithOptimizedData(optimizedData, tableName, question, data.split("\n").length - 1)
    } else {
      const quickOptimized = data.split("\n").slice(0, 31).join("\n") // 30 records ƒë·∫ßu
      return await answerQuestionWithOptimizedData(quickOptimized, tableName, question, data.split("\n").length - 1)
    }
  } catch (error) {
    console.error("‚ùå answerQuestionWithData failed:", error)
    return `‚ùå L·ªói khi tr·∫£ l·ªùi c√¢u h·ªèi: ${error}`
  }
}

export const testGroqAPI = async () => {
  const result = await testAllApiKeys()
  return {
    success: result.success,
    message: result.message,
    workingModel: AVAILABLE_MODELS[0],
  }
}
