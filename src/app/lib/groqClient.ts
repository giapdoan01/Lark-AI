import { Groq } from "groq-sdk"

// Danh s√°ch API keys
const API_KEYS = [
  process.env.NEXT_PUBLIC_GROQ_API_KEY_1 || "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",
  process.env.NEXT_PUBLIC_GROQ_API_KEY_2 || "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",
  process.env.NEXT_PUBLIC_GROQ_API_KEY_3 || "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",
  process.env.NEXT_PUBLIC_GROQ_API_KEY_4 || "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",
  process.env.NEXT_PUBLIC_GROQ_API_KEY_5 || "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",
].filter((key) => key && !key.includes("account") && key.startsWith("gsk_"))

const AVAILABLE_MODELS = [
  "llama-3.3-70b-versatile",
  "llama-3.1-8b-instant",
  "llama3-70b-8192",
  "llama3-8b-8192",
  "mixtral-8x7b-32768",
  "gemma-7b-it",
]

const createGroqClient = (apiKey: string): Groq => {
  return new Groq({
    apiKey: apiKey,
    dangerouslyAllowBrowser: true,
  })
}

// Helper function ƒë·ªÉ ph√¢n t√≠ch v·ªõi 1 key - di chuy·ªÉn l√™n tr∆∞·ªõc
const analyzeWithSingleKey = async (apiKey: string, keyIndex: number, prompt: string): Promise<string> => {
  try {
    console.log(`ü§ñ Ph√¢n t√≠ch v·ªõi key ${keyIndex + 1}`)

    const groq = createGroqClient(apiKey)

    for (const model of AVAILABLE_MODELS) {
      try {
        const completion = (await Promise.race([
          groq.chat.completions.create({
            model: model,
            messages: [
              {
                role: "user",
                content: prompt,
              },
            ],
            temperature: 0.7,
            max_tokens: 8000,
          }),
          new Promise((_, reject) => setTimeout(() => reject(new Error("Timeout 45s")), 45000)),
        ])) as any

        // Th√™m null checks
        if (!completion?.choices?.[0]?.message?.content) {
          console.log(`‚ö†Ô∏è Model ${model}: Kh√¥ng nh·∫≠n ƒë∆∞·ª£c response`)
          continue
        }

        const analysis = completion.choices[0].message.content || "Kh√¥ng c√≥ ph√¢n t√≠ch"
        console.log(`‚úÖ Ph√¢n t√≠ch th√†nh c√¥ng v·ªõi model ${model}`)

        return analysis
      } catch (modelError) {
        const errorMsg = modelError instanceof Error ? modelError.message : String(modelError)
        console.log(`‚ùå Model ${model}: ${errorMsg}`)
        continue
      }
    }

    throw new Error("T·∫•t c·∫£ models th·∫•t b·∫°i cho ph√¢n t√≠ch cu·ªëi")
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error)
    console.error(`‚ùå Ph√¢n t√≠ch cu·ªëi th·∫•t b·∫°i: ${errorMsg}`)
    return `‚ùå Kh√¥ng th·ªÉ ph√¢n t√≠ch: ${errorMsg}`
  }
}

// Function ƒë·ªÉ optimize/compress d·ªØ li·ªáu v·ªõi 1 API key
const optimizeDataChunk = async (
  apiKey: string,
  keyIndex: number,
  dataChunk: any[],
  chunkIndex: number,
  totalChunks: number,
): Promise<{ success: boolean; optimizedData: string; keyIndex: number; error?: string }> => {
  try {
    console.log(
      `üîß Key ${keyIndex + 1}: ƒêang optimize chunk ${chunkIndex + 1}/${totalChunks} (${dataChunk.length} records)`,
    )

    const groq = createGroqClient(apiKey)
    const rawData = JSON.stringify(dataChunk, null, 2)

    // Prompt ƒë·ªÉ optimize d·ªØ li·ªáu - KH√îNG ph√¢n t√≠ch, ch·ªâ t·ªëi ∆∞u format
    const optimizePrompt = `B·∫°n l√† m·ªôt data processor chuy√™n nghi·ªáp. Nhi·ªám v·ª• c·ªßa b·∫°n l√† OPTIMIZE d·ªØ li·ªáu sau ƒë·ªÉ gi·∫£m token nh∆∞ng GI·ªÆ NGUY√äN TO√ÄN B·ªò TH√îNG TIN:

D·ªÆ LI·ªÜU G·ªêC (Chunk ${chunkIndex + 1}/${totalChunks}):
${rawData}

Y√äU C·∫¶U:
1. ‚úÖ GI·ªÆ NGUY√äN t·∫•t c·∫£ th√¥ng tin quan tr·ªçng
2. ‚úÖ Lo·∫°i b·ªè null/empty values kh√¥ng c·∫ßn thi·∫øt  
3. ‚úÖ R√∫t g·ªçn format JSON (compact)
4. ‚úÖ Gi·ªØ nguy√™n recordId v√† t·∫•t c·∫£ fields c√≥ gi√° tr·ªã
5. ‚ùå KH√îNG ph√¢n t√≠ch, KH√îNG t√≥m t·∫Øt, KH√îNG gi·∫£i th√≠ch
6. ‚ùå KH√îNG thay ƒë·ªïi √Ω nghƒ©a d·ªØ li·ªáu

CH·ªà TR·∫¢ V·ªÄ D·ªÆ LI·ªÜU ƒê√É OPTIMIZE (JSON format), kh√¥ng c√≥ text th√™m:`

    // Th·ª≠ c√°c models
    for (const model of AVAILABLE_MODELS) {
      try {
        const completion = (await Promise.race([
          groq.chat.completions.create({
            model: model,
            messages: [
              {
                role: "user",
                content: optimizePrompt,
              },
            ],
            temperature: 0.1, // Th·∫•p ƒë·ªÉ ƒë·∫£m b·∫£o consistency
            max_tokens: 4000,
          }),
          new Promise((_, reject) => setTimeout(() => reject(new Error("Timeout 30s")), 30000)),
        ])) as any

        // Th√™m null checks
        if (!completion?.choices?.[0]?.message?.content) {
          console.log(`‚ö†Ô∏è Key ${keyIndex + 1} model ${model}: Kh√¥ng nh·∫≠n ƒë∆∞·ª£c response`)
          continue
        }

        const optimizedData = completion.choices[0].message.content.trim() || ""

        // Validate JSON ƒë·ªÉ ƒë·∫£m b·∫£o output h·ª£p l·ªá
        try {
          JSON.parse(optimizedData)
          console.log(`‚úÖ Key ${keyIndex + 1} optimize th√†nh c√¥ng v·ªõi model ${model}`)

          return {
            success: true,
            optimizedData: optimizedData,
            keyIndex: keyIndex,
          }
        } catch (jsonError) {
          console.log(`‚ö†Ô∏è Key ${keyIndex + 1} model ${model}: Invalid JSON output`)
          continue
        }
      } catch (modelError) {
        const errorMsg = modelError instanceof Error ? modelError.message : String(modelError)
        console.log(`‚ùå Key ${keyIndex + 1} model ${model}: ${errorMsg}`)

        if (errorMsg.includes("rate_limit")) {
          break // Kh√¥ng th·ª≠ model kh√°c n·∫øu rate limit
        }
        continue
      }
    }

    throw new Error("T·∫•t c·∫£ models th·∫•t b·∫°i cho key n√†y")
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : String(error)
    console.error(`‚ùå Key ${keyIndex + 1} optimize th·∫•t b·∫°i: ${errorMsg}`)

    return {
      success: false,
      optimizedData: "",
      keyIndex: keyIndex,
      error: errorMsg,
    }
  }
}

// Function ch√≠nh: Data Preprocessing Pipeline
export const preprocessDataWithPipeline = async (
  data: any[],
  tableName: string,
): Promise<{ success: boolean; optimizedData: string; analysis: string; keyUsage: any }> => {
  try {
    console.log(`üöÄ B·∫Øt ƒë·∫ßu Data Preprocessing Pipeline v·ªõi ${data.length} records`)

    if (!API_KEYS || API_KEYS.length === 0) {
      throw new Error("Kh√¥ng c√≥ API keys h·ª£p l·ªá")
    }

    // B∆Ø·ªöC 1: Chia d·ªØ li·ªáu th√†nh chunks
    const chunkSize = Math.ceil(data.length / Math.max(API_KEYS.length - 1, 1)) // Gi·ªØ l·∫°i 1 key cho ph√¢n t√≠ch cu·ªëi
    const chunks = []

    for (let i = 0; i < data.length; i += chunkSize) {
      chunks.push(data.slice(i, i + chunkSize))
    }

    console.log(`üìä B∆Ø·ªöC 1: Chia ${data.length} records th√†nh ${chunks.length} chunks`)

    // B∆Ø·ªöC 2: Optimize t·ª´ng chunk song song
    const optimizePromises = chunks.map((chunk, index) => {
      const keyIndex = index % (API_KEYS.length - 1) // Gi·ªØ l·∫°i key cu·ªëi cho ph√¢n t√≠ch
      const apiKey = API_KEYS[keyIndex]

      return optimizeDataChunk(apiKey, keyIndex, chunk, index, chunks.length)
    })

    console.log(`‚è≥ B∆Ø·ªöC 2: ƒêang optimize ${chunks.length} chunks song song...`)
    const optimizeResults = await Promise.all(optimizePromises)

    // Ki·ªÉm tra k·∫øt qu·∫£ optimize
    const successfulOptimizes = optimizeResults.filter((r) => r && r.success)
    const failedOptimizes = optimizeResults.filter((r) => r && !r.success)

    console.log(`üìä Optimize results: ${successfulOptimizes.length}/${optimizeResults.length} th√†nh c√¥ng`)

    if (!successfulOptimizes || successfulOptimizes.length === 0) {
      throw new Error("T·∫•t c·∫£ optimize requests ƒë·ªÅu th·∫•t b·∫°i")
    }

    // B∆Ø·ªöC 3: G·ªôp d·ªØ li·ªáu ƒë√£ optimize
    let combinedOptimizedData = "["
    successfulOptimizes.forEach((result, index) => {
      // Parse v√† merge JSON arrays
      try {
        const parsedData = JSON.parse(result.optimizedData)
        const dataArray = Array.isArray(parsedData) ? parsedData : [parsedData]

        if (index > 0) combinedOptimizedData += ","
        combinedOptimizedData += JSON.stringify(dataArray).slice(1, -1) // Remove [ ]
      } catch (parseError) {
        console.warn(`‚ö†Ô∏è Kh√¥ng th·ªÉ parse optimize result t·ª´ key ${result.keyIndex + 1}`)
      }
    })
    combinedOptimizedData += "]"

    console.log(`üìä B∆Ø·ªöC 3: ƒê√£ g·ªôp d·ªØ li·ªáu optimize (${combinedOptimizedData.length} characters)`)

    // B∆Ø·ªöC 4: Ph√¢n t√≠ch t·ªïng h·ª£p v·ªõi key cu·ªëi c√πng
    const finalKeyIndex = API_KEYS.length - 1
    const finalApiKey = API_KEYS[finalKeyIndex]

    if (!finalApiKey) {
      throw new Error("Kh√¥ng c√≥ API key cho ph√¢n t√≠ch cu·ªëi")
    }

    console.log(`ü§ñ B∆Ø·ªöC 4: Ph√¢n t√≠ch t·ªïng h·ª£p v·ªõi key ${finalKeyIndex + 1}`)

    const analysisPrompt = `B·∫°n l√† m·ªôt AI analyst chuy√™n nghi·ªáp. D∆∞·ªõi ƒë√¢y l√† TO√ÄN B·ªò d·ªØ li·ªáu t·ª´ b·∫£ng "${tableName}" ƒë√£ ƒë∆∞·ª£c optimize (${data.length} records):

${combinedOptimizedData}

ƒê√¢y l√† d·ªØ li·ªáu HO√ÄN CH·ªàNH t·ª´ ${data.length} b·∫£n ghi, ƒë√£ ƒë∆∞·ª£c optimize ƒë·ªÉ gi·∫£m token nh∆∞ng v·∫´n gi·ªØ nguy√™n to√†n b·ªô th√¥ng tin.

H√£y ph√¢n t√≠ch chi ti·∫øt:
1. üìä T·ªïng quan v·ªÅ ${data.length} records
2. üìà Th·ªëng k√™ quan tr·ªçng  
3. üîç Patterns v√† insights
4. üí° Nh·∫≠n x√©t v√† ƒë√°nh gi√°

Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, chi ti·∫øt v√† c√≥ c·∫•u tr√∫c.`

    const finalAnalysis = await analyzeWithSingleKey(finalApiKey, finalKeyIndex, analysisPrompt)

    const keyUsage = {
      totalKeys: API_KEYS.length,
      optimizeKeys: successfulOptimizes.length,
      analysisKey: 1,
      failedKeys: failedOptimizes.length,
      successRate: `${Math.round((successfulOptimizes.length / optimizeResults.length) * 100)}%`,
      chunks: chunks.length,
      recordsPerChunk: chunkSize,
      finalDataSize: combinedOptimizedData.length,
    }

    return {
      success: true,
      optimizedData: combinedOptimizedData,
      analysis: finalAnalysis,
      keyUsage: keyUsage,
    }
  } catch (error) {
    console.error("‚ùå Data Preprocessing Pipeline failed:", error)
    return {
      success: false,
      optimizedData: "",
      analysis: `‚ùå L·ªói preprocessing pipeline: ${error}`,
      keyUsage: { error: true },
    }
  }
}

// Function tr·∫£ l·ªùi c√¢u h·ªèi v·ªõi d·ªØ li·ªáu ƒë√£ optimize
export const answerQuestionWithOptimizedData = async (
  optimizedData: string,
  tableName: string,
  question: string,
  originalRecordCount: number,
): Promise<string> => {
  try {
    console.log(`ü§î Tr·∫£ l·ªùi c√¢u h·ªèi v·ªõi optimized data (${originalRecordCount} records)`)

    // S·ª≠ d·ª•ng key cu·ªëi c√πng ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi
    const finalKeyIndex = API_KEYS.length - 1
    const finalApiKey = API_KEYS[finalKeyIndex]

    if (!finalApiKey) {
      throw new Error("Kh√¥ng c√≥ API key ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi")
    }

    const questionPrompt = `B·∫°n l√† m·ªôt AI assistant th√¥ng minh. D∆∞·ªõi ƒë√¢y l√† TO√ÄN B·ªò d·ªØ li·ªáu t·ª´ b·∫£ng "${tableName}" (${originalRecordCount} records ƒë√£ ƒë∆∞·ª£c optimize):

${optimizedData}

ƒê√¢y l√† d·ªØ li·ªáu HO√ÄN CH·ªàNH t·ª´ ${originalRecordCount} b·∫£n ghi. H√£y d·ª±a v√†o d·ªØ li·ªáu n√†y ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch ch√≠nh x√°c v√† chi ti·∫øt.

C√¢u h·ªèi: ${question}

Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát:`

    return await analyzeWithSingleKey(finalApiKey, finalKeyIndex, questionPrompt)
  } catch (error) {
    console.error("‚ùå answerQuestionWithOptimizedData failed:", error)
    return `‚ùå L·ªói khi tr·∫£ l·ªùi c√¢u h·ªèi: ${error}`
  }
}

// Export function ch√≠nh thay th·∫ø analyzeDataWithParallelKeys
export const analyzeDataWithParallelKeys = preprocessDataWithPipeline

// Function tr·∫£ l·ªùi c√¢u h·ªèi - s·ª≠ d·ª•ng optimized data
export const answerQuestionWithData = async (
  data: any[],
  tableName: string,
  question: string,
  previousAnalysis?: string,
  optimizedData?: string,
): Promise<string> => {
  try {
    if (optimizedData && optimizedData.length > 0) {
      // N·∫øu c√≥ optimized data, s·ª≠ d·ª•ng n√≥
      return await answerQuestionWithOptimizedData(optimizedData, tableName, question, data.length)
    } else {
      // Fallback: t·∫°o optimized data nhanh
      const quickOptimized = JSON.stringify(data.slice(0, 30), null, 1) // 30 records ƒë·∫ßu
      return await answerQuestionWithOptimizedData(quickOptimized, tableName, question, data.length)
    }
  } catch (error) {
    console.error("‚ùå answerQuestionWithData failed:", error)
    return `‚ùå L·ªói khi tr·∫£ l·ªùi c√¢u h·ªèi: ${error}`
  }
}

// Test functions
export const testAllApiKeys = async (): Promise<{
  success: boolean
  message: string
  workingKeys: number
  totalKeys: number
  keyDetails: any[]
}> => {
  console.log(`üß™ Testing ${API_KEYS.length} API keys...`)

  const testPromises = API_KEYS.map(async (apiKey, index) => {
    try {
      const groq = createGroqClient(apiKey)

      const testCompletion = await groq.chat.completions.create({
        model: "llama-3.1-8b-instant",
        messages: [
          {
            role: "user",
            content: "Test: 1+1=?",
          },
        ],
        temperature: 0.1,
        max_tokens: 10,
      })

      // Th√™m null checks
      const response = testCompletion?.choices?.[0]?.message?.content || "No response"
      console.log(`‚úÖ Key ${index + 1}: OK`)

      return {
        keyIndex: index + 1,
        status: "success" as const,
        response: response,
        preview: `${apiKey.substring(0, 10)}...${apiKey.substring(apiKey.length - 4)}`,
      }
    } catch (error) {
      console.log(`‚ùå Key ${index + 1}: ${error}`)
      return {
        keyIndex: index + 1,
        status: "failed" as const,
        error: error instanceof Error ? error.message : String(error),
        preview: `${apiKey.substring(0, 10)}...${apiKey.substring(apiKey.length - 4)}`,
      }
    }
  })

  const results = await Promise.all(testPromises)
  const workingKeys = results.filter((r) => r.status === "success").length

  return {
    success: workingKeys > 0,
    message: `${workingKeys}/${API_KEYS.length} API keys ho·∫°t ƒë·ªông`,
    workingKeys: workingKeys,
    totalKeys: API_KEYS.length,
    keyDetails: results,
  }
}

// Backward compatibility
export const askAI = async (context: string, question: string): Promise<string> => {
  return await answerQuestionWithData([], "Unknown", question)
}

export const askAIWithFullData = async (data: any[], tableName: string, question: string): Promise<string> => {
  return await answerQuestionWithData(data, tableName, question)
}

export const askAIWithRawData = async (data: any[], tableName: string, question: string): Promise<string> => {
  return await answerQuestionWithData(data, tableName, question)
}

export const testGroqAPI = async () => {
  const result = await testAllApiKeys()
  return {
    success: result.success,
    message: result.message,
    workingModel: "pipeline",
  }
}

export const getAvailableModels = (): string[] => {
  return AVAILABLE_MODELS
}

export const getApiKeysInfo = () => {
  return {
    totalKeys: API_KEYS.length,
    keysPreview: API_KEYS.map(
      (key, index) => `Key ${index + 1}: ${key.substring(0, 10)}...${key.substring(key.length - 4)}`,
    ),
  }
}
